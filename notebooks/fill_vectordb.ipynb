{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to https://codeawake.com/blog/postgresql-vector-database\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# import pdfminer\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n",
    "from sqlalchemy import Text\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from pgvector.sqlalchemy import Vector\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pgai to setup necessary fucntions and tables in my vector DB, see https://github.com/timescale/pgai/tree/main/docs\n",
    "import pgai\n",
    "\n",
    "# pgai.install(DB_URL)\n",
    "# All of the pgai objects are installed into the ai schema.\n",
    "\n",
    "# install pgai command line tool by runnign following command in the terminal: uv add pgai[vectorizer-worker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create vector DB with postgresql\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Vector(Base):\n",
    "    __tablename__ = \"postgres\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    text: Mapped[str] = mapped_column(Text)\n",
    "    vector = mapped_column(\n",
    "        Vector(1024)\n",
    "    )  # set embedding dimensions, match with chosen embedding model\n",
    "    metadata_: Mapped[dict | None] = mapped_column(\"metadata\", JSONB)+\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"Vector(id={self.id}, text={self.text[:50]}..., metadata={self.metadata_})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.asyncio import async_sessionmaker, create_async_engine\n",
    "\n",
    "DB_URL = \"postgresql+asyncpg://admin:postgres@localhost:5432/postgres\"\n",
    "\n",
    "engine = create_async_engine(DB_URL)\n",
    "\n",
    "\n",
    "async def db_create():\n",
    "    async with engine.begin() as conn:\n",
    "        await conn.run_sync(Base.metadata.create_all)\n",
    "    print(engine.url, \"connected and tables created.\")\n",
    "\n",
    "\n",
    "engine = create_async_engine(DB_URL)\n",
    "Session = async_sessionmaker(engine, expire_on_commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_source_name = \"Koks et al - 2022 - Brief communication\"\n",
    "\"../\" + s.settings.PATH_DATA + f\"text_sources/{text_source_name}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract text from pdf with unstructured, good for RAG systems + document analysis\n",
    "from unstructured.partition.auto import partition\n",
    "import nltk  # unsupervised sentence tokenizer (https://www.nltk.org/api/nltk.tokenize.punkt.html)\n",
    "\n",
    "## load NLTK resource file for sentence tokenizer\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "\n",
    "text_source_name = \"Koks et al 2022 Brief communication\"\n",
    "\n",
    "blocks = partition(\n",
    "    filename=\"../\" + s.settings.PATH_DATA + f\"text_sources/{text_source_name}.pdf\"\n",
    ")\n",
    "for block in blocks:\n",
    "    print(f\"{block.category}: {block.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"../\" + s.settings.PATH_DATA + f\"text_sources/{text_source_name}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## extract text from pdf via pypdf\n",
    "# import pypdf\n",
    "# import json\n",
    "\n",
    "# def extract_text_from_pdf(file_path: str) -> str:\n",
    "#     text_list = []\n",
    "#     with open(file_path, \"rb\") as file:\n",
    "#         reader = pypdf.PdfReader(file)\n",
    "#         for page in reader.pages:\n",
    "#             text_list.append(page.extract_text())\n",
    "#             #text_list.append(page.extract_text() + \" \")\n",
    "#     return \"  \".join(text_list)\n",
    "\n",
    "\n",
    "# text_source_name = \"Koks et al - 2022 - Brief communication\"  # define which pdf should be read converted to txt\n",
    "# with open(\"../\" + s.PATH_DATA + f\"{text_source_name}.txt\", \"w+\") as f:\n",
    "#     json.dump(\n",
    "#         extract_text_from_pdf(\"../\" + s.PATH_DATA + f\"text_sources/{text_source_name}.pdf\"),\n",
    "#         f,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## extracting text from pdfs using pdfminer\n",
    "\n",
    "\n",
    "# docs = []\n",
    "# DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "\n",
    "# for filename in os.listdir(DOCS_DIR):\n",
    "#     if filename.endswith(\".pdf\"):\n",
    "#         file_path = os.path.join(DOCS_DIR, filename)\n",
    "#         text = extract_text(file_path)\n",
    "#         print(text)\n",
    "#         docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define recursive chunking, see, https://github.com/ruizguille/rag-from-scratch/blob/master/app/splitter.py\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "tiktoken_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "sentence_tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "\n",
    "\n",
    "def token_size(text):\n",
    "    return len(tiktoken_tokenizer.encode(text))\n",
    "\n",
    "\n",
    "def split_by_separator(text: str, sep: str) -> list[str]:\n",
    "    splits = text.split(sep)\n",
    "    res = [s + sep for s in splits[:-1]]\n",
    "    if splits[-1]:\n",
    "        res.append(splits[-1])\n",
    "    return res\n",
    "\n",
    "\n",
    "def split_sentences(text: str) -> list[str]:\n",
    "    spans = [s[0] for s in sentence_tokenizer.span_tokenize(text)]\n",
    "    return [text[spans[i] : spans[i + 1]] for i in range(len(spans) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## embedding model via pgai and containerized vectordb\n",
    "\n",
    "\n",
    "# def create_vectorizer(embedding_model, embeddings_dimensions):\n",
    "#     embeddings_view_name = (\n",
    "#         f'{\"essays\"}{\"_\"}{embedding_model.replace(\"-\", \"_\")}{\"_\"}{\"embeddings\"}'\n",
    "#     )\n",
    "\n",
    "#     with connect_db() as conn:\n",
    "#         with conn.cursor() as cur:\n",
    "#             cur.execute(\n",
    "#                 f\"\"\"\n",
    "#                 SELECT ai.create_vectorizer(\n",
    "#                 'essays'::regclass,\n",
    "#                 destination => {embeddings_view_name},\n",
    "#                 embedding => ai.embedding_ollama({embedding_model}, {embeddings_dimensions}),\n",
    "#                 chunking => ai.chunking_recursive_character_text_splitter('text', {s.chunk_size}, {s.chunk_overlap}),\n",
    "#                 formatting => ai.formatting_python_template('title: $title $chunk')\n",
    "#                 );\"\"\"\n",
    "#             )\n",
    "\n",
    "\n",
    "# # with connect_db() as conn:\n",
    "# #    with conn.cursor() as cur:\n",
    "# #         cur.execute(\"\"\"\n",
    "# #             SELECT ai.load_dataset(\n",
    "# #                     'sgoel9/xxx_essays',\n",
    "# #                     table_name => 'essays',\n",
    "# #                     if_table_exists => 'append');\n",
    "# #         \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## preprocess documents (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting text from pdfs using pdfminer\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "docs = []\n",
    "DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "\n",
    "for filename in os.listdir(DOCS_DIR):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(DOCS_DIR, filename)\n",
    "        text = extract_text(file_path)\n",
    "        print(text)\n",
    "        docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[2]  ## all docs in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove reference section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean from headers+footers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_source_name = \"Koks et al - 2022 - Brief communication\"  # define which pdf should be read converted to txt\n",
    "# with open(\"../\" + s.PATH_DATA + f\"{text_source_name}.txt\", \"w+\") as f:\n",
    "#     json.dump(\n",
    "#         extract_text_from_pdf(\"../\" + s.PATH_DATA + f\"text_sources/{text_source_name}.pdf\"),\n",
    "#         f,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## fill vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "from uuid import UUID, uuid4\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Dict, Any\n",
    "from pydantic import ConfigDict\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class EntryTextSource():\n",
    "#     def __init__(self, title: str, source: str, content: str, authors: str = None, metadata: dict = None):\n",
    "#         self.title = title\n",
    "#         self.source = source\n",
    "#         self.content= content\n",
    "#         self.authors = authors\n",
    "#         self.metadata = metadata\n",
    "\n",
    "\n",
    "# ensure a fix structure for text source entries\n",
    "class TextSource(BaseModel):\n",
    "    id: UUID = Field(\n",
    "        default_factory=uuid4\n",
    "    )  # make unique entry id to prevent overwriting\n",
    "    title: str\n",
    "    source: str\n",
    "    content: str\n",
    "    authors: Optional[str] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    # make model immutable\n",
    "    model_config = ConfigDict(frozen=True)\n",
    "\n",
    "\n",
    "?TextSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_entry = {\n",
    "#     \"title\": \"test title\",\n",
    "#     \"authors\": None,\n",
    "#     \"source\": \"test source\",\n",
    "#     \"content\": \"test \",\n",
    "#     \"metadata\": {\"tags\": [\"ahr_valley\", \"scientific_publication\"], \"published_date\": \"2022-11-29\"}\n",
    "# }\n",
    "\n",
    "# TextSource**test_entry).metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database and insert automatically all pdf files stored in data folder\n",
    "import json\n",
    "\n",
    "\n",
    "def fill_db(\n",
    "    entry: TextSource,\n",
    "):\n",
    "\n",
    "    conn = connect_db()\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    curs.execute(  # ai == make sure to takes the same schema for storing the entries and for running the vectorizer\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS text_source(\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            title TEXT, \n",
    "            authors TEXT, \n",
    "            source TEXT, \n",
    "            content TEXT, \n",
    "            metadata JSONB\n",
    "        );\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    curs.execute(\n",
    "        f\"\"\"\n",
    "        INSERT INTO text_source(title, authors, source, content, metadata) \n",
    "        VALUES\n",
    "        ('{entry.authors}',\n",
    "        '{entry.title}',\n",
    "        '{entry.source}',\n",
    "        '{entry.content}',\n",
    "        '{json.dumps(entry.metadata)}'\n",
    "        );\n",
    "        \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    curs.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill db automatically\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(DOCS_DIR):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        print(f\"fetching: {filename}\")\n",
    "\n",
    "        file_path = os.path.join(DOCS_DIR, filename)\n",
    "        text = extract_text(file_path)\n",
    "        filename = Path(filename).stem\n",
    "        authors, title = authors, title = (\n",
    "            re.compile(r\"(.+?)[0-9]{4}(.*)?\").search(filename).groups()\n",
    "        )\n",
    "\n",
    "        entry = {\n",
    "            \"authors\": authors.strip(),\n",
    "            \"title\": title.strip(),\n",
    "            \"source\": \"dummy source\",\n",
    "            \"content\": text,\n",
    "            \"metadata\": {\n",
    "                \"tags\": [\"ahr_valley\", \"dummy_publication_type\"],\n",
    "                \"published_date\": re.findall(r\"[0-9]{4}\", filename)[0],\n",
    "            },\n",
    "        }\n",
    "    fill_db(TextSource(**entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check entries\n",
    "conn = connect_db()\n",
    "curs = conn.cursor()\n",
    "\n",
    "curs.execute(\"SELECT * FROM nomic_embed_text_content_embeddings;\")\n",
    "rows = curs.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Clean up\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Mohr 2022 A multi-disciplinary analysis of the exceptional flood event of July 2021 in central Europe - Part 1 Event desciption and analysis\"\n",
    "\n",
    "authors, title = re.compile(r\"(.+?)[0-9]{4}(.*)?\").search(filename).groups()\n",
    "# authors, title = re.compile(r\"(.*)[0-9]{4}(.*)?\").search(filename).groups()\n",
    "authors, title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Load content from vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the context text from the response\n",
    "context = \"\".join(context_response[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## connect to postgres DB to receive context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_db(query):\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_db(\"SELECT chunk FROM text_source_content_embeddings;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## load decoder model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0  # nvidia gpu\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "# %env TORCH_CUDA_ARCH_LIST=8.6\n",
    "\n",
    "# settings for distributed computing\n",
    "%env WORLD_SIZE=1\n",
    "%env RANK=0\n",
    "%env LOCAL_RANK=0\n",
    "\n",
    "# NOTE: # WORLD_SIZE: each GPU corresponds to one process (world = no. of processes within a group), processes communicate with each other enabling eg., distributed training\n",
    "# NOTE: # RANK: IDs of the processes, ranging from 0 up to WORLD_SIZE - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check env-vars\n",
    "# %env PYTORCH_CUDA_ALLOC_CONF\n",
    "# os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set default location to store model before loading transformers\n",
    "os.environ[\"HF_HOME\"] = (\n",
    "    \"/home/a-buch/Documents/TUB_DWN/_PROJECTS/CI-impacts-information-retrieval/notebooks/huggingface_mirror/\"\n",
    ")\n",
    "\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    GPTJForQuestionAnswering,\n",
    ")\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code block needs only need to be adapted for cluster\n",
    "# # for own laptop use random port number and localhost (127.0.0.1) as placeholder\n",
    "\n",
    "%env MASTER_ADDR=127.0.0.1\n",
    "%env MASTER_PORT=6006\n",
    "\n",
    "# # Initialize distributed computing\n",
    "rank = int(os.environ[\"RANK\"])\n",
    "device = torch.device(f\"cuda:{rank}\")\n",
    "torch.cuda.set_device(device)\n",
    "torch.distributed.init_process_group(backend=\"nccl\")\n",
    "# # torch.distributed.init_process_group(backend='nccl', init_method='env://', rank = torch.cuda.device_count(), world_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check cuda device number and ids\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"GPU: \", i, torch.cuda.get_device_name(i))  # get current device name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### generate prompt\n",
    "\n",
    "Use `Jinja` a templating language that enables to write Python-like code and syntax.\n",
    "Tje library is used to better manage versions of prompts by separating prompt structure and content\n",
    "May use alongside pydantic for validation\\\n",
    "Tested here : try to return for the LLM outputs also the entry IDs \\\n",
    "Further info, see:\n",
    "* https://python.useinstructor.com/concepts/templating/#context-is-available-to-pydantic-validators \n",
    "and for implementing jinja in HF pipeline:\n",
    "* https://huggingface.co/docs/transformers/chat_templating_writing#tool-responses\n",
    "* https://huggingface.co/docs/transformers/v4.57.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Abstract. Germany, Belgium and the Netherlands were hit\n",
    "by extreme precipitation and flooding in July 2021. This\n",
    "brief communication provides an overview of the impacts to\n",
    "large-scale critical infrastructure systems and how recovery\n",
    "has progressed. The results show that Germany and Belgium\n",
    "were particularly affected, with many infrastructure assets\n",
    "severely damaged or completely destroyed. Impacts range\n",
    "from completely destroyed bridges and sewage systems, to\n",
    "severely damaged schools and hospitals. We find that (largescale)\n",
    "risk assessments, often focused on larger (river) flood\n",
    "events, do not find these local, but severe, impacts due to critical\n",
    "infrastructure failures. This may be the result of limited\n",
    "availability of validation material. As such, this brief communication\n",
    "not only will help to better understand how critical\n",
    "infrastructure can be affected by flooding, but also can be\n",
    "used as validation material for future flood risk assessments.\\n\\n\n",
    "1 Introduction\\n\n",
    "In mid-July 2021, a persistent low-pressure system caused\n",
    "extreme precipitation in parts of the Belgian, German and\n",
    "Dutch catchments of the Meuse and Rhine rivers. This led\n",
    "to record-breaking water levels and severe flooding (Mohr\n",
    "et al., 2022). Comparable heavy precipitation events in this\n",
    "area have never been registered in most of the affected areas\n",
    "before (Kreienkamp et al., 2021). The German states most affected\n",
    "include Rhineland-Palatinate (Rheinland-Pfalz), with\n",
    "damage to the Ahr River valley (Ahrtal), several regions in\n",
    "the Eiffel National Park, to the city of Trier. Flooding in\n",
    "Belgium was concentrated in the Vesdre River valley (districts\n",
    "of Pepinster, Ensival and Verviers), the Meuse River\n",
    "valley (Maaseik, Liége), the Gete River valley (Herk-de-Stad\n",
    "and Halen) and southeast Brussels (Wavre). The Netherlands\n",
    "experienced flooding, mostly concentrated in the southern\n",
    "district of Limburg. In total, at least 220 casualties have\n",
    "been reported, with insured loss estimates of approximately\n",
    "EUR 150 million–EUR 250 million in the Netherlands (Verbond\n",
    "voor Verzekeraars, 2022), EUR 2.2 billion in Belgium\n",
    "(Assuralia, 2022) and EUR 8.2 billion (GDV, 2022)\n",
    "in Germany. The event caused major damages to residential\n",
    "and commercial structures and to many critical infrastructure\n",
    "(CI) assets. Not only vital functions for first responders\n",
    "were affected (e.g. hospitals, fire departments), but also railways,\n",
    "bridges and utility networks (e.g. water and electricity\n",
    "supply) were severely damaged, expecting to take months to\n",
    "years to fully rebuild. \\n\\n\n",
    "CI is often considered to be the backbone of a wellfunctioning\n",
    "society (Hall et al., 2016), which is particularly\n",
    "eminent during natural hazards and disasters. For instance,\n",
    "failure of electricity or telecommunication services immediately\n",
    "causes disruptions in the day-to-day functioning of people\n",
    "and businesses, including those outside the directly affected\n",
    "area. Despite the (academic) agreement that failure of\n",
    "infrastructure systems may cause (large-scale) societal disruptions\n",
    "(Garschagen and Sandholz, 2018; Hallegatte et al.,\n",
    "2019; Fekete and Sandholz, 2021), empirical evidence on the\n",
    "impacts of extreme weather events on these systems is still\n",
    "Published by Copernicus Publications on behalf of the European Geosciences Union.\n",
    "3832 E. E. Koks et al.: Flood impacts to infrastructure\n",
    "limited. \\n\\n This brief communication provides an overview of\n",
    "the observed flood impacts to large-scale infrastructure systems\n",
    "during the 2021 mid-July western European flood event\n",
    "and how reconstruction of these large-scale systems has progressed.\n",
    "Next, we highlight how some of these observations\n",
    "compare to academic modelling approaches. We conclude\n",
    "with suggestions on moving forward in CI risk modelling,\n",
    "based on the lessons learned from this extreme event. \\n\\n\n",
    "2 Critical infrastructure impacts\\n\n",
    "2.1 Transport infrastructure\\n\n",
    "In Germany, road and railway infrastructure was severely\n",
    "damaged as documented exemplarily in Fig. 1. Cost estimates\n",
    "reach up to EURO2 billion Euro (MDR, 2021). More\n",
    "than 130 km of motorways were closed directly after the\n",
    "event, of which 50 km were still closed two months later,\n",
    "with an estimated repair cost of EUR100 million (Hauser,\n",
    "2021). Of the 112 bridges in the flooded 40 km of the Ahr\n",
    "valley (Rhineland-Palatinate), 62 bridges were destroyed,\n",
    "13 were severely damaged and only 35 were in operation\n",
    "a month after the flood event (MDR, 2021). Over 74 km\n",
    "of roads, paths and bridges in the Ahr valley have been\n",
    "(critically) damaged. In some cases, repairs are expected to\n",
    "take months to years (Zeit Online, 2021). For example, major\n",
    "freeway sections, including parts of the A1 motorway,\n",
    "were closed until early 2022 (24Rhein, 2022). In addition,\n",
    "about 50 000 cars were damaged, causing insurance claims of\n",
    "some EUR 450 million (ADAC, 2021). The German railway\n",
    "provider Deutsche Bahn expects asset damages of around\n",
    "EUR 1.3 billion. Among other things, 180 level crossings,\n",
    "almost 40 signal boxes, over 1000 catenary and signal masts,\n",
    "and 600 km of tracks were destroyed, as well as energy supply\n",
    "systems, elevators and lighting systems (MDR, 2021).\n",
    "As of 11 April 2022, 14 of the affected rail stretches are\n",
    "fully functional again. The less damaged stretches were functional\n",
    "again within 3 months, while some of the most damaged\n",
    "sections in the Ahr valley are expected to be finished\n",
    "by the end of 2025 (DB, 2022). In Belgium, approximately\n",
    "10 km of railway tracks and 3000 sleeper tracks have to be replaced;\n",
    "50 km of catenary needs to be repaired; and 70 000 t\n",
    "of railway track bed needs to be placed, with estimated\n",
    "costs between EUR 30 million–EUR 50 million (Rozendaal,\n",
    "2021a). Most damages have been repaired within 2 weeks.\n",
    "The most severely damaged railway line (between the villages\n",
    "of Spa and Pepinster) was reopened again on 3 October\n",
    "2021 (Rozendaal, 2021b). In the Netherlands, no largescale\n",
    "damage has been reported to transport infrastructure. A\n",
    "few national highways were partly flooded (e.g. the A76 in\n",
    "both directions) or briefly closed (<3 d) because of the potential\n",
    "of flooding. \\n\n",
    "Most likely due to relative low-flow velocities,\n",
    "damage to Dutch national road infrastructure was\n",
    "limited. Several railway sections were closed (e.g. the railway\n",
    "section between Maastricht and Liége) and some damage\n",
    "occurred to the railway infrastructure, in particular to the\n",
    "electronic “track circuit” devices and saturated railway embankments\n",
    "(Prorail, 2021).\\n\\n\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# question = \"Which societal or economic impacts of infrastructure failures are mentioned in the text?\"\n",
    "question = \"Which impacts of infrastructure failures are mentioned in the text? Categorize the output by the type of infrastructure, societal or economic impacts, the location and possibly the time of the infrastructure failure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Electricity and gas supply\\n\n",
    "# At the peak of the event, around 200 000 people experienced\n",
    "# power outages in Germany. Electricity infrastructure was\n",
    "# severely damaged in North Rhine-Westphalia and Rhineland-\n",
    "# Palatinate. However, within 2 d around 50 % of the power\n",
    "# was restored through repairs and temporary fixes. Within 8\n",
    "# weeks, no emergency power generators were required any-\n",
    "# more, with most of the power infrastructure restored in Ger-\n",
    "# many’s affected areas. Some areas, however, only had perma-\n",
    "# nent power infrastructure after 6 months (Westnetz, 2022).\n",
    "# The gas distribution network in the Ahr valley was severely\n",
    "# damaged. Approximately 133 km of natural gas pipelines,\n",
    "# 8500 gas metres, 3400 house pressure regulators, 7220 of the\n",
    "# approximately 8000 household connections, and 31 systems\n",
    "# measuring and regulating gas pressure have been damaged\n",
    "# or destroyed (SWR, 2021). Gas supply was almost fully re-\n",
    "# stored within 4.5 months after the flood event (Energienetze\n",
    "# Mittelrhein, 2021). In Belgium, approximately 41 500 peo-\n",
    "# ple experienced power outages at the peak of the event. This\n",
    "# was the result of both damaged and deliberately switched-\n",
    "# off electrical cabinets to prevent serious damages. It took\n",
    "# around 3 weeks to fully restore power. Similar to Germany,\n",
    "# severe damage had been observed to the gas network. In the\n",
    "# villages around Liége, such as Chaudfontaine and Pepinster\n",
    "# (Belgium), gas supply was fully recovered within 5 months\n",
    "# (Grosjean, 2021; De Wolf, 2021). In the Netherlands, 1000–\n",
    "# 2000 households experienced a loss of electricity supply at\n",
    "# the peak of the event. Between 100 to 200 households had\n",
    "# no gas supply. Within several days, electricity supply was re-\n",
    "# stored (Task Force Fact Finding Hoogwater, 2021).\\n\\n\n",
    "# 2.3 Drinking water supply and wastewater\\n\n",
    "# In the region of Rhineland-Palatinate (Germany), most drink-\n",
    "# ing water supply was restored within 2 months (Hochwasser\n",
    "# Ahr, 2021a). However, sewage treatment plants in Alte-\n",
    "# nahr, Mayschoss and Sinzig had been largely destroyed\n",
    "# (Hochwasser Ahr, 2021b), and it is expected to take at least\n",
    "# 1.5 years to fully repair most sewage treatment plants. Emer-\n",
    "# gency sewage treatment plants have been built in the mean-\n",
    "# time (GA, 2021). In the Erft region 7 out of 31 wastewater\n",
    "# facilities had been destroyed. Many facilities reported pollu-\n",
    "# tion of oil and diesel, forming layers up to 15 cm thick (Kuhn,\n",
    "# 2021). In addition, much of the groundwater (and soil) in\n",
    "# the flood region was mixed with oil (from destroyed residen-\n",
    "# tial oil tanks), chemicals such as fertilizers (from wineries\n",
    "# and other agriculture) and chemicals from nearby industrial\n",
    "# plants. In Sinzig, 3.6 × 106 L of oil–water mixture was re-\n",
    "# cycled, gaining 3600 m3 of oil, to be reused for heating and\n",
    "# industrial usage (Kuhn, 2021). In the heavily destroyed town\n",
    "# of Bad Münstereifel (in the state of North Rhine-Westphalia),\n",
    "# drinking water supply was re-established within 5 d after the\n",
    "# flood event (most frequently through emergency tanks), and\n",
    "# about 50 % of the city centre was reconnected to the fresh-\n",
    "# water network shortly thereafter however, water had to be\n",
    "# boiled before consumption until about 1 month later (Bad\n",
    "# Münstereifel, 2021). In Belgium, several towns experienced\n",
    "# disruptions in water supply (in particular as a result of pol-\n",
    "# lution). Directly after the event, approximately 3400 families\n",
    "# had no access to potable water. Within less than a week, this\n",
    "# was reduced to around 1650 families (Terzake, 2021). It took,\n",
    "# however, 6 months to rebuild the permanent water supply in-\n",
    "# frastructure (SWDE, 2022). In the Netherlands, little to no\n",
    "# problems have been recorded with regards to water supply.\\n\\n\n",
    "# 2.4 Solid waste\\n\n",
    "# We found no information regarding direct impact on solid-\n",
    "# waste facilities as a result of the flood event. However, there\n",
    "# is a large pressure on the solid-waste sector to clean the af-\n",
    "# fected areas; 1 month after the event, we observed dozens\n",
    "# of large temporary waste fills and frequent incidences of\n",
    "# oil pollution in Rhineland-Palatinate during a field visit.\n",
    "# In the Ahrweiler district alone, the flood caused as much\n",
    "# solid waste as normally would be collected over 30 years.\n",
    "# In Belgium, the amount of solid waste is estimated around\n",
    "# 160 000 t, stored at several places, such as the abandoned\n",
    "# highway track A601. This highway has been used for approx-\n",
    "# imately 9 months as a temporary storage for debris (Cou-\n",
    "# plez, 2022). In the Netherlands, there have been primarily\n",
    "# problems with waste deposits along the river banks, which\n",
    "# is mostly the solid waste transported by the river from fur-\n",
    "# ther upstream. Thousands of tonnes of tree debris (logs and\n",
    "# deadwood) were recycled in the Ahr valley. For instance, the\n",
    "# towns of Höenningen and Mayschoss, served as major recy-\n",
    "# cle hubs. Per day, approximately 500 t of wood debris was\n",
    "# transported, cut, chipped and recycled into firewood, which\n",
    "# continued for at least 6 weeks after the flood (Gather, 2021).\\n\n",
    "# 2.5Telecommunication\\n\n",
    "# In Germany, all severely affected areas experienced dis-\n",
    "# ruption of mobile network services. Within the region of\n",
    "# Rhineland-Palatinate, it took 2 weeks to ensure 100 % cover-\n",
    "# age again through emergency communication masts. Within\n",
    "# 1 month, most of the network was restored to pre-disaster ser-\n",
    "# vice provision. After 5 months, broadband has also been re-\n",
    "# stored in the most affected areas, which started in most areas\n",
    "# only after power infrastructure was rebuilt (Westnetz, 2021).\n",
    "# In Belgium, it has taken around 11 months to restore connec-\n",
    "# tion to the last communities within the affected area. In the\n",
    "# Netherlands, approximately 7000 households were affected\n",
    "# by disrupted telecommunication service. This was primarily\n",
    "# due to flooded telecommunication infrastructure in the direct\n",
    "# vicinity of flooded houses. However, some distribution cab-\n",
    "# inets were flooded as well, with the largest flooded cabinet\n",
    "# affecting around 700 households. Due to damaged bridges,\n",
    "# several fibre cables were damaged. Five telecommunication\n",
    "# masts were affected as well, but “tuning” of the network\n",
    "# ensured that the service disruption was kept to a minimum\n",
    "# (Task Force Fact Finding Hoogwater, 2021).\\n\\n\n",
    "# 2.6 Healthcare and education\\n\n",
    "# In Germany, an estimated 180 general-practitioner practices\n",
    "# have been affected by the flood event. Impacts range from\n",
    "# completely destroyed to unable to operate due to a lack\n",
    "# of running water and electricity (Ärzte Zeitung, 2021). Af-\n",
    "# ter 1.5 months, medical care was guaranteed again in the\n",
    "# most affected regions in Rhineland-Palatinate (Hochwasser\n",
    "# Ahr, 2021c). In the state of North Rhine-Westphalia, approx-\n",
    "# imately 68 hospitals have been affected, of which several\n",
    "# have been affected severely and will take at least 1.5 years\n",
    "# to be rebuilt (Fig. 2). Direct damages are estimated to be\n",
    "# at least EUR 100 million to repair all medical facilities (Ko-\n",
    "# rzilius, 2021). In the town of Eschweiler (Germany), for ex-\n",
    "# ample, the basement of the hospital was flooded, as well as\n",
    "# the outbuildings and the entire outdoor area. The power sup-\n",
    "# ply collapsed, the entire building technology was destroyed\n",
    "# and some 300 patients had to be evacuated by helicopter.\n",
    "# Property damage is expected to be around EUR 50 million.\n",
    "# Within 3.5 weeks, the hospital was partly operational, and\n",
    "# within 3 months, all hospital operations continued normally\n",
    "# (SAH Eschweiler, 2021). The Mutterhaus Ehrang hospital in\n",
    "# Trier (Germany) is now permanently closed as the hospital is\n",
    "# too severely damaged to rebuild. Furthermore, in the region\n",
    "# of Rhineland-Palatinate (Germany), 19 daycare centres and\n",
    "# 17 schools suffered damage from the floods, affecting more\n",
    "# than 8000 students (Staib, 2021). Approximately 4 months\n",
    "# after the flood event, the district of Bad Neuenahr-Ahrweiler\n",
    "# established emergency educational facilities using 297 con-\n",
    "# tainers that serve as classrooms, offices and dining facilities\n",
    "# for more than 800 students (Wiesbadener Kurier, 2021). In\n",
    "# Belgium, various rural clinics have been affected and were\n",
    "# unable to provide any services. Concurrently, in the most af-\n",
    "# fected areas, general-practitioner facilities have been com-\n",
    "# pletely destroyed (Le Spécialiste, 2021). In the Netherlands,\n",
    "# one nursing home was flooded, and one hospital was evacu-\n",
    "# ated as a precautionary measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pdfminer.high_level import extract_text\n",
    "\n",
    "# sys.path.append(\"../\")\n",
    "# import src.settings as s\n",
    "\n",
    "# DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "# filename = \"Koks et al 2022 Brief communication.pdf\"\n",
    "\n",
    "# file_path = os.path.join(DOCS_DIR, filename)\n",
    "# koks_et_al_text = extract_text(file_path)\n",
    "\n",
    "\n",
    "# context = koks_et_al_text\n",
    "\n",
    "# # question = \"Which societal or economic impacts of infrastructure failures are mentioned in the text?\"\n",
    "# question = \"Which impacts of infrastructure failures are mentioned in the text? Categorize the output by the type of infrastructure, societal or economic impacts, the location and possibly the time of the infrastructure failure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "\n",
    "# TODO move template to separate file and load via get_template(), define conditions (e.g. user is technical or not)\n",
    "# Example code: https://medium.com/@alecgg27895/jinja2-prompting-a-guide-on-using-jinja2-templates-for-prompt-management-in-genai-applications-e36e5c1243cf\n",
    "# test instead of user_type (see: {% block user_type %}) the modification of question in regard to CI impact types (Tier 1,2,3 and 4 )\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "    You are an AI assistant and should use ONLY the provided context to answer the following question. \n",
    "    Try to be as specific as possible in your answer (bullet points), mention the impacts as numerical information along the location of the impact, and refer to the citations provided in the context.\n",
    "\n",
    "    Question: {{ question }}\n",
    " \n",
    "    {% if messages %}\n",
    "    Conversation history:\n",
    "    {% for m in messages %}\n",
    "    - ({{ m.role }}): {{ m.content }}\n",
    "    {% endfor %}\n",
    "    {% endif %}\n",
    "\n",
    "    Context:\n",
    "    {% for item in context %}\n",
    "    - {{ item.text }} (Citation: {{ item.citation }})\n",
    "    {% endfor %}\n",
    "    \n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "template = Template(prompt_template)\n",
    "\n",
    "# TODO change to categorize\n",
    "messages = [{\"role\": \"user\", \"content\": \"Can you help me understand this topic?\"}]\n",
    "\n",
    "contexts = [\n",
    "    {\n",
    "        \"text\": context,\n",
    "        \"citation\": \"Koks et al., 2022\",\n",
    "    },  # TODO use author names or Primary keys from DB\n",
    "    # {\"text\": context, \"citation\": \"Meier et al., 2025\"},\n",
    "]\n",
    "\n",
    "rendered_prompt = template.render(\n",
    "    context=contexts,\n",
    "    question=question,\n",
    "    # messages=messages\n",
    ")\n",
    "# print(rendered_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Test GPT-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # https://github.com/huggingface/transformers/issues/12448\n",
    "\n",
    "# # Download model and tokenizer\n",
    "# model_name = \"EleutherAI/gpt-j-6B\" # \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# base_dir = \"./huggingface_mirror\"\n",
    "# model_dir = base_dir + \"/hub/\"\n",
    "\n",
    "# # Run once to download the model and cache it locally\n",
    "# snapshot_download(\n",
    "#     repo_id=\"EleutherAI/gpt-j-6B\", # \"meta-llama/Llama-2-7b-chat-hf\",  # \"google/gemma-3-4b-it\",\n",
    "#     cache_dir=model_dir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "# # empyty CUDA cache\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init class for decoder and tokenizer\n",
    "\n",
    "\n",
    "# class DecoderModel:\n",
    "#     def __init__(self):\n",
    "#         login(\n",
    "#             token=os.environ[\"HUGGINGFACE_TOKEN\"]\n",
    "#         )  # TODO replace by using pydantic settings\n",
    "\n",
    "#         # model_name = \"google/gemma-3-4b-it\" # \"kallidavidson/TinyBERT_General_4L_312D\"  # \"huawei-noah/TinyBERT_General_4L_312D\" # - for QA - less DWL\n",
    "#         # model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#         model_name = \"EleutherAI/gpt-j-6B\" #\"distilbert-base-multilingual-cased\"\n",
    "#         base_dir = \"./huggingface_mirror\"  # use default dir in .cache/\n",
    "#         model_dir = base_dir + \"/hub/\"  # + \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "#         print(model_dir)\n",
    "\n",
    "#         # quantization config\n",
    "#         # Load model with 4-bit quantization if applicable (use 4-bit integer instead of 32b floats) --> reduce the required VRAM for model application\n",
    "#         # see, https://huggingface.co/docs/transformers/quantization\n",
    "#         bnb_config = BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type=\"nf4\",\n",
    "#             bnb_4bit_compute_dtype=torch.float16,\n",
    "#         )\n",
    "\n",
    "#         self.pipeline, self.tokenizer = self.initialize_model(\n",
    "#             model_name, model_dir, bnb_config\n",
    "#         )\n",
    "\n",
    "#     def initialize_model(self, model_name: str, model_dir: str = None, bnb_config=None):\n",
    "\n",
    "#         # Model and Tokenizer initialization\n",
    "#         if not os.path.exists(model_dir):\n",
    "#             print(\"Model directory not found. Downloading model...\")\n",
    "#             os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#             device = transformers.infer_device()\n",
    "#             print(f\"Using device: {device}\")\n",
    "#             model = GPTJForQuestionAnswering.from_pretrained(\n",
    "#                 model_name,\n",
    "#                 dtype=\"auto\",\n",
    "#                 attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "#                 # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "#                 quantization_config=bnb_config,\n",
    "#                 # max_memory={0: \"2GB\", 1: \"10GB\"},  # distribute memory across GPUs\n",
    "#                 tp_plan=\"auto\",\n",
    "#             )\n",
    "#             model.save_pretrained(model_dir)\n",
    "#             tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "#             tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "#             print(\"Downloaded model and tokenizer\")\n",
    "\n",
    "#         else:\n",
    "#             print(f\"Using locally saved model from {model_dir}\")\n",
    "\n",
    "#             model = GPTJForQuestionAnswering.from_pretrained(\n",
    "#                 model_name,\n",
    "#                 cache_dir=model_dir,\n",
    "#                 local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "#                 # dtype=\"auto\",\n",
    "#                 dtype=torch.float16,\n",
    "#                 attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "#                 # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "#                 quantization_config=bnb_config,\n",
    "#                 # max_memory={0: \"2GB\", 1: \"10GB\"},  # distribute memory across GPUs\n",
    "#                 tp_plan=\"auto\",  # automatically use a tensor parallelism plan based on predefined configuration of the model (i.e. partition model on both GPUs)\n",
    "#             )\n",
    "#             print(\"Tensor parallel plan:\", model._tp_plan)\n",
    "\n",
    "#             tokenizer = AutoTokenizer.from_pretrained(\n",
    "#                 model_name, use_fast=True, cache_dir=model_dir, # use fast Rust-based tokenizer, when possible\n",
    "#             )\n",
    "\n",
    "#         # reduce further memory usage\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = model.to(device)\n",
    "#         model.use_checkpointing = True\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         # Pipeline setup for question answering\n",
    "#         pipeline = transformers.pipeline(  # load model locally from wsl .cache\\\n",
    "#             \"question-answering\",  # task defining which pipeline is returned\n",
    "#             #\"text-generation\",\n",
    "#             model=model,\n",
    "#             tokenizer=tokenizer, #(return_tensors=\"pt\"),  # load specific tokenizer based on model-name (via AutoTokenizer) ensuring text is tokenized in accordance to the way the model was trained\n",
    "#             max_new_tokens=256,\n",
    "#             dtype=torch.float16,\n",
    "#             # low_cpu_mem_usage=True,\n",
    "#             device_map=\"auto\",\n",
    "#         )\n",
    "#         return pipeline, tokenizer\n",
    "\n",
    "#     def generate_response(self, question: str, context: str):\n",
    "#         # Preparing the input prompts\n",
    "#         prompt = {\"question\": question, \"context\": context}\n",
    "#         # messages = [\n",
    "#         #     {\"role\": \"system\", \"content\": context},\n",
    "#         #     {\"role\": \"user\", \"content\": question},\n",
    "#         # ]\n",
    "#         # # Combine messages into a single string prompt\n",
    "#         # prompt = \"\\n\".join([f'{msg[\"role\"]}: {msg[\"content\"]}' for msg in messages])\n",
    "#         # print(\"prompt:\", messages[1][\"content\"])\n",
    "\n",
    "#         # Generating responses\n",
    "#         sequences = self.pipeline(\n",
    "#             prompt,  # for text generation\n",
    "#             # question=question, context=context,  # for eQA\n",
    "#             max_new_tokens=256,\n",
    "#             do_sample=True,\n",
    "#             eos_token_id=self.tokenizer.eos_token_id,\n",
    "#         )\n",
    "#         # Extracting and returning the generated text\n",
    "#         return sequences\n",
    "\n",
    "\n",
    "# decoder_model = DecoderModel()\n",
    "# response = decoder_model.generate_response(question=question, context=context)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "\n",
    "Abstract. Germany, Belgium and the Netherlands were hit\n",
    "by extreme precipitation and flooding in July 2021. This\n",
    "brief communication provides an overview of the impacts to\n",
    "large-scale critical infrastructure systems and how recovery\n",
    "has progressed. The results show that Germany and Belgium\n",
    "were particularly affected, with many infrastructure assets\n",
    "severely damaged or completely destroyed. Impacts range\n",
    "from completely destroyed bridges and sewage systems, to\n",
    "severely damaged schools and hospitals. We find that (largescale)\n",
    "risk assessments, often focused on larger (river) flood\n",
    "events, do not find these local, but severe, impacts due to critical\n",
    "infrastructure failures. This may be the result of limited\n",
    "availability of validation material. As such, this brief communication\n",
    "not only will help to better understand how critical\n",
    "infrastructure can be affected by flooding, but also can be\n",
    "used as validation material for future flood risk assessments.\n",
    "\n",
    "\n",
    "1 Introduction\n",
    "In mid-July 2021, a persistent low-pressure system caused\n",
    "extreme precipitation in parts of the Belgian, German and\n",
    "Dutch catchments of the Meuse and Rhine rivers. This led\n",
    "to record-breaking water levels and severe flooding (Mohr\n",
    "et al., 2022). Comparable heavy precipitation events in this\n",
    "area have never been registered in most of the affected areas\n",
    "before (Kreienkamp et al., 2021). The German states most affected\n",
    "include Rhineland-Palatinate (Rheinland-Pfalz), with\n",
    "damage to the Ahr River valley (Ahrtal), several regions in\n",
    "the Eiffel National Park, to the city of Trier. Flooding in\n",
    "Belgium was concentrated in the Vesdre River valley (districts\n",
    "of Pepinster, Ensival and Verviers), the Meuse River\n",
    "valley (Maaseik, Liége), the Gete River valley (Herk-de-Stad\n",
    "and Halen) and southeast Brussels (Wavre). The Netherlands\n",
    "experienced flooding, mostly concentrated in the southern\n",
    "district of Limburg. In total, at least 220 casualties have\n",
    "been reported, with insured loss estimates of approximately\n",
    "EUR 150 million–EUR 250 million in the Netherlands (Verbond\n",
    "voor Verzekeraars, 2022), EUR 2.2 billion in Belgium\n",
    "(Assuralia, 2022) and EUR 8.2 billion (GDV, 2022)\n",
    "in Germany. The event caused major damages to residential\n",
    "and commercial structures and to many critical infrastructure\n",
    "(CI) assets. Not only vital functions for first responders\n",
    "were affected (e.g. hospitals, fire departments), but also railways,\n",
    "bridges and utility networks (e.g. water and electricity\n",
    "supply) were severely damaged, expecting to take months to\n",
    "years to fully rebuild. \n",
    "\n",
    "\n",
    "CI is often considered to be the backbone of a wellfunctioning\n",
    "society (Hall et al., 2016), which is particularly\n",
    "eminent during natural hazards and disasters. For instance,\n",
    "failure of electricity or telecommunication services immediately\n",
    "causes disruptions in the day-to-day functioning of people\n",
    "and businesses, including those outside the directly affected\n",
    "area. Despite the (academic) agreement that failure of\n",
    "infrastructure systems may cause (large-scale) societal disruptions\n",
    "(Garschagen and Sandholz, 2018; Hallegatte et al.,\n",
    "2019; Fekete and Sandholz, 2021), empirical evidence on the\n",
    "impacts of extreme weather events on these systems is still\n",
    "Published by Copernicus Publications on behalf of the European Geosciences Union.\n",
    "3832 E. E. Koks et al.: Flood impacts to infrastructure\n",
    "limited. \n",
    "\n",
    " This brief communication provides an overview of\n",
    "the observed flood impacts to large-scale infrastructure systems\n",
    "during the 2021 mid-July western European flood event\n",
    "and how reconstruction of these large-scale systems has progressed.\n",
    "Next, we highlight how some of these observations\n",
    "compare to academic modelling approaches. We conclude\n",
    "with suggestions on moving forward in CI risk modelling,\n",
    "based on the lessons learned from this extreme event. \n",
    "\n",
    "\n",
    "2 Critical infrastructure impacts\n",
    "2.1 Transport infrastructure\n",
    "In Germany, road and railway infrastructure was severely\n",
    "damaged as documented exemplarily in Fig. 1. Cost estimates\n",
    "reach up to EURO2 billion Euro (MDR, 2021). More\n",
    "than 130 km of motorways were closed directly after the\n",
    "event, of which 50 km were still closed two months later,\n",
    "with an estimated repair cost of EUR100 million (Hauser,\n",
    "2021). Of the 112 bridges in the flooded 40 km of the Ahr\n",
    "valley (Rhineland-Palatinate), 62 bridges were destroyed,\n",
    "13 were severely damaged and only 35 were in operation\n",
    "a month after the flood event (MDR, 2021). Over 74 km\n",
    "of roads, paths and bridges in the Ahr valley have been\n",
    "(critically) damaged. In some cases, repairs are expected to\n",
    "take months to years (Zeit Online, 2021). For example, major\n",
    "freeway sections, including parts of the A1 motorway,\n",
    "were closed until early 2022 (24Rhein, 2022). In addition,\n",
    "about 50 000 cars were damaged, causing insurance claims of\n",
    "some EUR 450 million (ADAC, 2021). The German railway\n",
    "provider Deutsche Bahn expects asset damages of around\n",
    "EUR 1.3 billion. Among other things, 180 level crossings,\n",
    "almost 40 signal boxes, over 1000 catenary and signal masts,\n",
    "and 600 km of tracks were destroyed, as well as energy supply\n",
    "systems, elevators and lighting systems (MDR, 2021).\n",
    "As of 11 April 2022, 14 of the affected rail stretches are\n",
    "fully functional again. The less damaged stretches were functional\n",
    "again within 3 months, while some of the most damaged\n",
    "sections in the Ahr valley are expected to be finished\n",
    "by the end of 2025 (DB, 2022). In Belgium, approximately\n",
    "10 km of railway tracks and 3000 sleeper tracks have to be replaced;\n",
    "50 km of catenary needs to be repaired; and 70 000 t\n",
    "of railway track bed needs to be placed, with estimated\n",
    "costs between EUR 30 million–EUR 50 million (Rozendaal,\n",
    "2021a). Most damages have been repaired within 2 weeks.\n",
    "The most severely damaged railway line (between the villages\n",
    "of Spa and Pepinster) was reopened again on 3 October\n",
    "2021 (Rozendaal, 2021b). In the Netherlands, no largescale\n",
    "damage has been reported to transport infrastructure. A\n",
    "few national highways were partly flooded (e.g. the A76 in\n",
    "both directions) or briefly closed (<3 d) because of the potential\n",
    "of flooding. \n",
    "\n",
    "Most likely due to relative low-flow velocities,\n",
    "damage to Dutch national road infrastructure was\n",
    "limited. Several railway sections were closed (e.g. the railway\n",
    "section between Maastricht and Liége) and some damage\n",
    "occurred to the railway infrastructure, in particular to the\n",
    "electronic “track circuit” devices and saturated railway embankments\n",
    "(Prorail, 2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpcloud\n",
    "\n",
    "client = nlpcloud.Client(\"gpt-j\", \"your_token\", gpu=True)\n",
    "\n",
    "generation = client.generation(\n",
    "    f\"\"\"\n",
    "    Context: More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR100 million (Hauser, 2021). Of the 112 bridges in the flooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the flood event (MDR, 2021).\n",
    "    Question: How many bridges were destroyed in the Ahr valley during the 2021 flood event?\n",
    "    Answer: 62\n",
    "    ###\n",
    "    Context: More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR100 million (Hauser, 2021). Of the 112 bridges in the flooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the flood event (MDR, 2021).\n",
    "    Question: How many bridges were in operation a month after the flood event in the Ahr valley?\n",
    "    Answer: 35\n",
    "    ###\n",
    "    Context: More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR100 million (Hauser, 2021). Of the 112 bridges in the flooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the flood event (MDR, 2021).\n",
    "    Question: How many bridges were at least affected by the flood event in the Ahr valley?\n",
    "    Answer: 77\n",
    "    ###\n",
    "    Context:  In total, at least 220 casualties have been reported, with insured loss estimates of approximately EUR 150 million–EUR 250 million in the Netherlands (Verbond voor Verzekeraars, 2022), EUR 2.2 billion in Belgium (Assuralia, 2022) and EUR 8.2 billion (GDV, 2022) in Germany. The event caused major damages to residential and commercial structures and to many critical infrastructure (CI) assets. \n",
    "    Question: How high are the estimated insured losses in Germany?\n",
    "    Answer: EUR 8.2 billion\n",
    "    ###\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    # min_length=1,\n",
    "    max_length=20,\n",
    "    length_no_input=True,\n",
    "    end_sequence=\"###\",\n",
    "    remove_end_sequence=True,\n",
    "    remove_input=True,\n",
    ")\n",
    "print(generation[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "\n",
    "# traceback.clear_frames(sys.last_traceback)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# try:\n",
    "#     a = 1/0\n",
    "# except Exception as e:\n",
    "#     exc_tuple = sys.exc_info()\n",
    "#     print(e, exc_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "# traceback.clear_frames(sys.last_traceback)\n",
    "\n",
    "## empty CUDA cache\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### Test llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init class for decoder and tokenizer\n",
    "\n",
    "\n",
    "# class DecoderModel:\n",
    "#     def __init__(self):\n",
    "#         login(\n",
    "#             token=os.environ[\"HUGGINGFACE_TOKEN\"]\n",
    "#         )  # TODO replace by using pydantic settings\n",
    "\n",
    "#         # model_name = \"google/gemma-3-4b-it\" # \"kallidavidson/TinyBERT_General_4L_312D\"  # \"huawei-noah/TinyBERT_General_4L_312D\" # - for QA - less DWL\n",
    "#         model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#         # \"distilbert-base-multilingual-cased\"\n",
    "#         base_dir = \"./huggingface_mirror\"  # use default dir in .cache/\n",
    "#         model_dir = base_dir + \"/hub/\"  # + \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "#         print(model_dir)\n",
    "\n",
    "#         # quantization config\n",
    "#         # Load model with 4-bit quantization if applicable (use 4-bit integer instead of 32b floats) --> reduce the required VRAM for model application\n",
    "#         # see, https://huggingface.co/docs/transformers/quantization\n",
    "#         bnb_config = BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type=\"nf4\",\n",
    "#             bnb_4bit_compute_dtype=torch.float16,\n",
    "#         )\n",
    "\n",
    "#         self.pipeline, self.tokenizer = self.initialize_model(\n",
    "#             model_name, model_dir, bnb_config\n",
    "#         )\n",
    "\n",
    "#     def initialize_model(self, model_name: str, model_dir: str = None, bnb_config=None):\n",
    "\n",
    "#         # Model and Tokenizer initialization\n",
    "#         if not os.path.exists(model_dir):\n",
    "#             print(\"Model directory not found. Downloading model...\")\n",
    "#             os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#             device = transformers.infer_device()\n",
    "#             print(f\"Using device: {device}\")\n",
    "#             model = AutoModelForCausalLM.from_pretrained(\n",
    "#                 model_name,\n",
    "#                 local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "#                 dtype=\"auto\",\n",
    "#                 attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "#                 # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "#                 quantization_config=bnb_config,\n",
    "#                 # max_memory={0: \"2GB\", 1: \"10GB\"},  # distribute memory across GPUs\n",
    "#                 )\n",
    "#             model.save_pretrained(model_dir)\n",
    "#             tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "#             tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "#             print(\"Downloaded model and tokenizer\")\n",
    "\n",
    "#         else:\n",
    "#             print(f\"Using locally saved model from {model_dir}\")\n",
    "\n",
    "#             model = AutoModelForCausalLM.from_pretrained(\n",
    "#                 model_name,\n",
    "#                 cache_dir=model_dir,\n",
    "#                 local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "#                 dtype=\"auto\",\n",
    "#                 attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "#                 # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "#                 quantization_config=bnb_config,\n",
    "#                 # tp_plan=\"auto\",  # automatically use a tensor parallelism plan based on predefined configuration of the model (i.e. partition model on both GPUs)\n",
    "#             )\n",
    "#             # print(\"Tensor parallel plan:\", model._tp_plan)\n",
    "\n",
    "#             tokenizer = AutoTokenizer.from_pretrained(\n",
    "#                 model_name,\n",
    "#                 use_fast=True,\n",
    "#                 cache_dir=model_dir,  # use fast Rust-based tokenizer, when possible\n",
    "#             )\n",
    "\n",
    "#         # reduce further memory usage\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = model.to(device)\n",
    "#         model.use_checkpointing = True\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         # Pipeline setup for question answering\n",
    "#         pipeline = transformers.pipeline(  # load model locally from wsl .cache\\\n",
    "#             \"text-generation\",\n",
    "#             # \"question-answering\",  # task defining which pipeline is returned\n",
    "#             model=model,\n",
    "#             tokenizer=tokenizer,\n",
    "#             # (return_tensors=\"pt\"),  # load specific tokenizer based on model-name (via AutoTokenizer) ensuring text is tokenized in accordance to the way the model was trained\n",
    "#             max_new_tokens=500,\n",
    "#             device_map=\"auto\",\n",
    "#         )\n",
    "#         return pipeline, tokenizer\n",
    "\n",
    "#     def generate_response(self, rendered_prompt: str):\n",
    "\n",
    "#         # Generating responses\n",
    "#         sequences = self.pipeline(\n",
    "#             rendered_prompt,  # jinja template\n",
    "#             max_new_tokens=500, # lower values truncate the LLM response too much\n",
    "#             do_sample=True,\n",
    "#             # top_k=10,\n",
    "#             # top_p=0.5,\n",
    "#             # num_return_sequences=1,\n",
    "#             eos_token_id=self.tokenizer.eos_token_id,\n",
    "#             return_full_text=False,  # allow bullet point answers\n",
    "#         )\n",
    "#         # Extracting and returning the generated text\n",
    "#         return sequences\n",
    "\n",
    "\n",
    "# decoder_model = DecoderModel()\n",
    "# response = decoder_model.generate_response(rendered_prompt=rendered_prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "# # empyty CUDA cache\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Llama with json output + NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move template to separate file and load via get_template(), define conditions (e.g. user is technical or not)\n",
    "# TODo make pydantic class model for expected JSON output\n",
    "\n",
    "# Example code: https://medium.com/@alecgg27895/jinja2-prompting-a-guide-on-using-jinja2-templates-for-prompt-management-in-genai-applications-e36e5c1243cf\n",
    "# test instead of user_type (see: {% block user_type %}) the modification of question in regard to CI impact types (Tier 1,2,3 and 4 )\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "    You are an expert analyst assistant and should use ONLY the provided context to answer the following question:\n",
    "\n",
    "    Question: \"{{ question }}\"\n",
    "    \n",
    "    Return ONLY valid JSON in the following list format:\n",
    "    [{\n",
    "        \"infrastructure_type\": \"...\",\n",
    "        \"damage\": \"...\",\n",
    "        \"economic_impact\": \"...\",\n",
    "        \"location\": \"...\",\n",
    "        \"time\": \"...\",\n",
    "        \"duration\": \"...\"\n",
    "    }]\n",
    "\n",
    "    Each nested dictionary describes one failure case.\n",
    "    Do not add commentary or text outside the JSON.\n",
    "\n",
    "\n",
    "    Context:\n",
    "    {% for item in context %}\n",
    "    - {{ item.text }} (Citation: {{ item.citation }})\n",
    "    {% endfor %}\n",
    "    \n",
    "\n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "template = Template(prompt_template)\n",
    "\n",
    "\n",
    "context = [\n",
    "    {\n",
    "        \"text\": context,\n",
    "        \"citation\": \"Koks et al., 2022\",\n",
    "    },  # TODO use author names or Primary keys from DB\n",
    "    # {\"text\": context, \"citation\": \"Meier et al., 2025\"},\n",
    "]\n",
    "\n",
    "rendered_prompt = template.render(\n",
    "    context=context,\n",
    "    question=question,\n",
    "    # messages=messages\n",
    ")\n",
    "# print(rendered_prompt)\n",
    "\n",
    "\n",
    "## left overs\n",
    "#  Try to be as specific as possible in your answer (bullet points), mention the impacts as numerical information along the location of the impact, and refer to the citations provided in the context.\n",
    "# # Extract information about infrastructure failures based on the following question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])  # TODO replace by using pydantic settings\n",
    "\n",
    "# model_name = \"google/gemma-3-4b-it\" # \"kallidavidson/TinyBERT_General_4L_312D\"  # \"huawei-noah/TinyBERT_General_4L_312D\" # - for QA - less DWL\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# \"distilbert-base-multilingual-cased\"\n",
    "base_dir = \"./huggingface_mirror\"  # use default dir in .cache/\n",
    "model_dir = base_dir + \"/hub/\"  # + \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "print(model_dir)\n",
    "\n",
    "# quantization config\n",
    "# Load model with 4-bit quantization if applicable (use 4-bit integer instead of 32b floats) --> reduce the required VRAM for model application\n",
    "# see, https://huggingface.co/docs/transformers/quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "# Model and Tokenizer initialization\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Model directory not found. Downloading model...\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    device = transformers.infer_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "        dtype=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "        # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "        quantization_config=bnb_config,\n",
    "        # max_memory={0: \"2GB\", 1: \"10GB\"},  # distribute memory across GPUs\n",
    "    )\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "    print(\"Downloaded model and tokenizer\")\n",
    "\n",
    "else:\n",
    "    print(f\"Using locally saved model from {model_dir}\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=model_dir,\n",
    "        local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "        dtype=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "        # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "        quantization_config=bnb_config,\n",
    "        # tp_plan=\"auto\",  # automatically use a tensor parallelism plan based on predefined configuration of the model (i.e. partition model on both GPUs)\n",
    "    )\n",
    "    # print(\"Tensor parallel plan:\", model._tp_plan)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        use_fast=True,\n",
    "        cache_dir=model_dir,  # use fast Rust-based tokenizer, when possible\n",
    "    )\n",
    "\n",
    "\n",
    "# reduce further memory usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.use_checkpointing = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Pipeline setup for question answering\n",
    "pipe = transformers.pipeline(  # load model locally from wsl .cache\\\n",
    "    \"text-generation\",\n",
    "    # \"question-answering\",  # task defining which pipeline is returned\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # (return_tensors=\"pt\"),  # load specific tokenizer based on model-name (via AutoTokenizer) ensuring text is tokenized in accordance to the way the model was trained\n",
    "    max_new_tokens=512,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Generating responses\n",
    "response = pipe(\n",
    "    rendered_prompt,  # jinja template\n",
    "    max_new_tokens=512,  # lower values truncate the LLM response too much\n",
    "    # do_sample=True,\n",
    "    # top_k=10,\n",
    "    # top_p=0.5,\n",
    "    temperature=0.2,  # generate repetitive / predictable output\n",
    "    # num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,  # allow bullet point answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the generated text (safe guard in case pipeline returns list/dict structure)\n",
    "if isinstance(response, list) and response:\n",
    "    first = response[0]\n",
    "    if isinstance(first, dict) and \"generated_text\" in first:\n",
    "        print(first[\"generated_text\"].strip())\n",
    "    else:\n",
    "        print(str(first))\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX workaround for truncated llm output due to small max_token settings\n",
    "resp = \"\"\"\n",
    "[\n",
    "        {\n",
    "            \"infrastructure_type\": \"Roads\",\n",
    "            \"damage\": \"130 km of motorways were closed directly after the event, of which 50 km were still closed two months later with an estimated repair cost of EUR100 million.\",\n",
    "            \"economic_impact\": \"insurance claims of some EUR 450 million\",\n",
    "            \"location\": \"Germany\",\n",
    "            \"time\": \"immediately after the event\"\n",
    "        },\n",
    "        {\n",
    "            \"infrastructure_type\": \"Railways\",\n",
    "            \"damage\": \"112 bridges in the flooded 40 km of the Ahr valley were destroyed, severely damaged or only in operation a month after the flood event.\",\n",
    "            \"economic_impact\": \"asset damages of around EUR 1.3 billion\",\n",
    "            \"location\": \"Germany\",\n",
    "            \"time\": \"immediately after the event\",\n",
    "        },\n",
    "        {\n",
    "            \"infrastructure_type\": \"Energy supply systems\",\n",
    "            \"damage\": \"about 50 000 cars were damaged, causing insurance claims of some EUR 450 million\",\n",
    "            \"economic_impact\": \"EUR 450 million\",\n",
    "            \"location\": \"Germany\",\n",
    "            \"time\": \"immediately after the event\"\n",
    "        },\n",
    "        {\n",
    "            \"infrastructure_type\": \"Bridges\",\n",
    "            \"damage\": \"62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the flood event\",\n",
    "            \"economic_impact\": \"estimated repair cost of EUR100 million\",\n",
    "            \"location\": \"Germany\",\n",
    "            \"time\": \"immediately after the event\"\n",
    "        }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")  #  automatic linebreaks and multi-line cells.\n",
    "pd.set_option(\"display.colheader_justify\", \"left\")\n",
    "\n",
    "# resp  = first[\"generated_text\"].strip()\n",
    "resp = resp.replace(\"\\n\", \"\")\n",
    "# resp = resp.replace(\"`\", '\"')\n",
    "\n",
    "df = pd.read_json(resp)\n",
    "df = df.style.set_properties(**{\"text-align\": \"left\"})\n",
    "df\n",
    "#\n",
    "# pd.DataFrame.from_dict(, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b8517",
   "metadata": {},
   "source": [
    "### response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the generated text (safe guard in case pipeline returns list/dict structure)\n",
    "if isinstance(response, list) and response:\n",
    "    first = response[0]\n",
    "    if isinstance(first, dict) and \"generated_text\" in first:\n",
    "        print(first[\"generated_text\"].strip())\n",
    "    else:\n",
    "        print(str(first))\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dda5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response[0][\"generated_text\"].split(\"Economic impacts:\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f2e45",
   "metadata": {},
   "source": [
    "Instructions:  You are an AI assistant and should use ONLY the provided context to answer the following question. \n",
    "    Try to be as specific as possible in your answer (bullet points) and refer to the citations provided in the context.\n",
    "\n",
    "question = \"Which impacts of infrastructure failures are mentioned in the text? Categorize the output by the type of infrastructure, societal or economic impacts, the location and possibly the time of the infrastructure failure.\"\n",
    "\n",
    "\n",
    "The impacts of infrastructure failures are mentioned in the text as follows:\n",
    "\n",
    "    1. Transport infrastructure: The text mentions that roads and railways were severely damaged in Germany, with estimated repair costs of up to EUR 2 billion. In Belgium, approximately 10 km of railway tracks and 3000 sleeper tracks need to be replaced, and in the Netherlands, damage to national road infrastructure was limited but some railway sections were closed.\n",
    "\n",
    "    2. Societal impacts: The text notes that the flooding caused major disruptions in the day-to-day functioning of people and businesses, including those outside the directly affected area.\n",
    "\n",
    "    3. Economic impacts: The text estimates insured loss estimates of approximately EUR 150 million–EUR 250 million in the Netherlands, EUR 2.2 billion in Belgium, and EUR 8.2 billion in Germany.\n",
    "\n",
    "    4. Location and time: The impacts were observed in mid-July 2021 in parts of Belgium, Germany, and the Netherlands.\n",
    "\n",
    "    5. Type of infrastructure: The text mentions damages to large-scale infrastructure systems, including transport infrastructure (roads and railways), societal infrastructure (hospitals, fire departments, and utility networks), and economic infrastructure (railways, bridges, and utility networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ce6c8",
   "metadata": {},
   "source": [
    "The impacts of infrastructure failures mentioned in the text are:\n",
    "\n",
    "* Road and railway infrastructure damage in Germany, with costs estimated to reach up to EURO2 billion.\n",
    "* Destruction of 62 bridges and severe damage to 13 bridges in the Ahr valley in Germany.\n",
    "* Closure of 112 bridges in the Ahr valley and 74 km of roads, paths, and bridges in the area.\n",
    "* Damage to residential and commercial structures.\n",
    "* Disruptions to railways, including the destruction of 180 level crossings, signal boxes, and 1000 catenary and signal masts.\n",
    "* Energy supply system damage.\n",
    "* Damage to elevators and lighting systems.\n",
    "* Limited damage to transport infrastructure in Belgium.\n",
    "* Damage to railway infrastructure in Belgium, including the replacement of 10 km of railway tracks and 3000 sleeper tracks, and the repair of 50 km of catenary.\n",
    "* Damage to railway infrastructure in the Netherlands, including the closure of a few national highways and damage to the electronic “track circuit”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[0].keys())\n",
    "# print(response[0][\"generated_text\"].split(\"user: \")[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cbf1d",
   "metadata": {},
   "source": [
    "#### check response versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f19617",
   "metadata": {},
   "source": [
    "[{'generated_text': 'system: \\nAbstract. Germany, Belgium and the Netherlands were hit\\nby extreme precipitation and flooding in July 2021. This\\nbrief communication provides an overview of the impacts to\\nlarge-scale critical infrastructure systems and how recovery\\nhas progressed. The results show that Germany and Belgium\\nwere particularly affected, with many infrastructure assets\\nseverely damaged or completely destroyed. Impacts range\\nfrom completely destroyed bridges and sewage systems, to\\nseverely damaged schools and hospitals. We find that (largescale)\\nrisk assessments, often focused on larger (river) flood\\nevents, do not find these local, but severe, impacts due to critical\\ninfrastructure failures. This may be the result of limited\\navailability of validation material. As such, this brief communication\\nnot only will help to better understand how critical\\ninfrastructure can be affected by flooding, but also can be\\nused as validation material for future flood risk assessments.\\n\\n\\n1 Introduction\\nIn mid-July 2021, a persistent low-pressure system caused\\nextreme precipitation in parts of the Belgian, German and\\nDutch catchments of the Meuse and Rhine rivers. This led\\nto record-breaking water levels and severe flooding (Mohr\\net al., 2022). Comparable heavy precipitation events in this\\narea have never been registered in most of the affected areas\\nbefore (Kreienkamp et al., 2021). The German states most affected\\ninclude Rhineland-Palatinate (Rheinland-Pfalz), with\\ndamage to the Ahr River valley (Ahrtal), several regions in\\nthe Eiffel National Park, to the city of Trier. Flooding in\\nBelgium was concentrated in the Vesdre River valley (districts\\nof Pepinster, Ensival and Verviers), the Meuse River\\nvalley (Maaseik, Liége), the Gete River valley (Herk-de-Stad\\nand Halen) and southeast Brussels (Wavre). The Netherlands\\nexperienced flooding, mostly concentrated in the southern\\ndistrict of Limburg. In total, at least 220 casualties have\\nbeen reported, with insured loss estimates of approximately\\nEUR 150 million–EUR 250 million in the Netherlands (Verbond\\nvoor Verzekeraars, 2022), EUR 2.2 billion in Belgium\\n(Assuralia, 2022) and EUR 8.2 billion (GDV, 2022)\\nin Germany. The event caused major damages to residential\\nand commercial structures and to many critical infrastructure\\n(CI) assets. Not only vital functions for first responders\\nwere affected (e.g. hospitals, fire departments), but also railways,\\nbridges and utility networks (e.g. water and electricity\\nsupply) were severely damaged, expecting to take months to\\nyears to fully rebuild. \\n\\n\\nCI is often considered to be the backbone of a wellfunctioning\\nsociety (Hall et al., 2016), which is particularly\\neminent during natural hazards and disasters. For instance,\\nfailure of electricity or telecommunication services immediately\\ncauses disruptions in the day-to-day functioning of people\\nand businesses, including those outside the directly affected\\narea. Despite the (academic) agreement that failure of\\ninfrastructure systems may cause (large-scale) societal disruptions\\n(Garschagen and Sandholz, 2018; Hallegatte et al.,\\n2019; Fekete and Sandholz, 2021), empirical evidence on the\\nimpacts of extreme weather events on these systems is still\\nPublished by Copernicus Publications on behalf of the European Geosciences Union.\\n3832 E. E. Koks et al.: Flood impacts to infrastructure\\nlimited. \\n\\n This brief communication provides an overview of\\nthe observed flood impacts to large-scale infrastructure systems\\nduring the 2021 mid-July western European flood event\\nand how reconstruction of these large-scale systems has progressed.\\nNext, we highlight how some of these observations\\ncompare to academic modelling approaches. We conclude\\nwith suggestions on moving forward in CI risk modelling,\\nbased on the lessons learned from this extreme event. \\n\\n\\n2 Critical infrastructure impacts\\n2.1 Transport infrastructure\\nIn Germany, road and railway infrastructure was severely\\ndamaged as documented exemplarily in Fig. 1. Cost estimates\\nreach up to EURO2 billion Euro (MDR, 2021). More\\nthan 130 km of motorways were closed directly after the\\nevent, of which 50 km were still closed two months later,\\nwith an estimated repair cost of EUR100 million (Hauser,\\n2021). Of the 112 bridges in the flooded 40 km of the Ahr\\nvalley (Rhineland-Palatinate), 62 bridges were destroyed,\\n13 were severely damaged and only 35 were in operation\\na month after the flood event (MDR, 2021). Over 74 km\\nof roads, paths and bridges in the Ahr valley have been\\n(critically) damaged. In some cases, repairs are expected to\\ntake months to years (Zeit Online, 2021). For example, major\\nfreeway sections, including parts of the A1 motorway,\\nwere closed until early 2022 (24Rhein, 2022). In addition,\\nabout 50 000 cars were damaged, causing insurance claims of\\nsome EUR 450 million (ADAC, 2021). The German railway\\nprovider Deutsche Bahn expects asset damages of around\\nEUR 1.3 billion. Among other things, 180 level crossings,\\nalmost 40 signal boxes, over 1000 catenary and signal masts,\\nand 600 km of tracks were destroyed, as well as energy supply\\nsystems, elevators and lighting systems (MDR, 2021).\\nAs of 11 April 2022, 14 of the affected rail stretches are\\nfully functional again. The less damaged stretches were functional\\nagain within 3 months, while some of the most damaged\\nsections in the Ahr valley are expected to be finished\\nby the end of 2025 (DB, 2022). In Belgium, approximately\\n10 km of railway tracks and 3000 sleeper tracks have to be replaced;\\n50 km of catenary needs to be repaired; and 70 000 t\\nof railway track bed needs to be placed, with estimated\\ncosts between EUR 30 million–EUR 50 million (Rozendaal,\\n2021a). Most damages have been repaired within 2 weeks.\\nThe most severely damaged railway line (between the villages\\nof Spa and Pepinster) was reopened again on 3 October\\n2021 (Rozendaal, 2021b). In the Netherlands, no largescale\\ndamage has been reported to transport infrastructure. A\\nfew national highways were partly flooded (e.g. the A76 in\\nboth directions) or briefly closed (<3 d) because of the potential\\nof flooding. \\n\\nMost likely due to relative low-flow velocities,\\ndamage to Dutch national road infrastructure was\\nlimited. Several railway sections were closed (e.g. the railway\\nsection between Maastricht and Liége) and some damage\\noccurred to the railway infrastructure, in particular to the\\nelectronic “track circuit” devices and saturated railway embankments\\n(Prorail, 2021).\\nuser: Which impacts of infrastructure failures are mentioned in the text? Categorize the output by the type of infrastructure, societal or economic impacts, the location and possibly the time of the infrastructure failure.'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa933b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(response)):\n",
    "    # print(f\"{response[i]['generated_text']}\" ) # \\nscore: {response[i]['score']}\")\n",
    "    print(response[i][\"generated_text\"].split(\"assistant:\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user: Which societal or economic impacts of infrastructure failures are mentioned in the text?\n",
    "\n",
    "# assistant: In Germany, the most severe impacts of the floods on critical infrastructure were reported in the Ahr valley and the Rhine river valley. These impacts included the destruction of infrastructure assets (e.g. Bridges, railway infrastructure) and severe damages to residential and commercial structures. CI infrastructure such as water and electricity supply and telecommunication networks were severely damaged, with estimated costs of EUR 150 million–EUR 250 million in the Netherlands (Verbond voor Verzekeraars, 2022). The floods also impacted the availability of water, sewage and wastewater services, and resulted in significant power outages for a short period. In Belgium, significant damage was reported to railway infrastructure, including the destruction of track bed and sleepers, while the most severe impacts were reported in the Ahr valley (approximately 10 km of railway tracks and 3000 sleeper tracks) as well as in the Rhine river valley (approximately 50 km of catenary and 220 km of tracks). The most damaged railway line (between the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "?response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a810a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "# empyty CUDA cache\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     login(token=os.environ.get('HUGGINGFACE_TOKEN'))\n",
    "\n",
    "#     self.pipeline, self.tokenizer = self.initialize_model(model_name)\n",
    "\n",
    "# def initialize_model(self, model_name):\n",
    "#     # Tokenizer initialization\n",
    "#     tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=200)\n",
    "# print(tokenizer.batch_decode(outputs)[0])\n",
    "\n",
    "# model = transformers.pipeline(model=\"google/gemma-3-4b-it\") # \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\") #\n",
    "# model(question=\"Where do I live?\", text_inputs=\"My name is Wolfgang and I live in Berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be38089",
   "metadata": {},
   "outputs": [],
   "source": [
    "?AutoTokenizer.from_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Document cleaning and unifying \n",
    "\n",
    "Parse documents into unified document representation called DoclingDocument, which captures information such as main content and headers and layout information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "from matplotlib import pyplot as plt\n",
    "from langchain_docling import DoclingLoader\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    AcceleratorOptions,\n",
    "    AcceleratorDevice,\n",
    ")\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "from docling.document_converter import DocumentConverter, FormatOption\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s\n",
    "from src.document_cleaning import remove_references, remove_headers_footers\n",
    "\n",
    "\n",
    "# Docling pipeline configs\n",
    "accelerator_options = AcceleratorOptions(\n",
    "    num_threads=4, device=AcceleratorDevice.AUTO\n",
    ")  # use GPU + multi-threading\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = (\n",
    "    True  # identify tables as such just not to have them in the TextItems later\n",
    ")\n",
    "pipeline_options.accelerator_options = accelerator_options\n",
    "pipeline_options.force_backend_text = True\n",
    "\n",
    "\n",
    "DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "PARSED_TEXT_DIR = \"../\" + s.settings.PATH_DATA + \"parsed_documents/\"\n",
    "\n",
    "\n",
    "md_dir = Path(PARSED_TEXT_DIR)\n",
    "md_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup converter for PDF and markdown\n",
    "converted = DocumentConverter(\n",
    "    allowed_formats=[InputFormat.PDF, InputFormat.MD],\n",
    "    format_options={\n",
    "        InputFormat.PDF: FormatOption(\n",
    "            pipeline_cls=StandardPdfPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "            backend=PyPdfiumDocumentBackend,\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the different layouts of the pdf files into unified markdown format incl. sub/section titles, tables, caption text etc\n",
    "for pdf_filename in os.listdir(DOCS_DIR):\n",
    "    if pdf_filename.endswith(\".pdf\"):\n",
    "\n",
    "        md_filename = f\"{Path(pdf_filename).stem}.md\"\n",
    "\n",
    "        pdf_filepath = os.path.join(DOCS_DIR, Path(pdf_filename))\n",
    "        md_filepath = os.path.join(PARSED_TEXT_DIR, Path(md_filename))\n",
    "        cleaned_md_filepath = md_filepath.replace(\".md\", \"_cleaned.md\")\n",
    "\n",
    "        if os.path.exists(md_filepath):\n",
    "            print(\n",
    "                f\"Markdown file '{md_filepath}' already exists. Skipping conversion and cleaning.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nFetching: {pdf_filename}\")\n",
    "\n",
    "        print(\"Remove reference section\")\n",
    "        pdf_text = extract_text(pdf_filepath)\n",
    "        pdf_text_no_references = remove_references(pdf_text)\n",
    "\n",
    "        # FIXME remove workaround of saving pdf as markdown and reading it again as Docling.Document\n",
    "        with open(md_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pdf_text_no_references)\n",
    "\n",
    "        # FIXME with DocLoader\n",
    "        # loader = DoclingLoader(md_filepath)\n",
    "        # md_text = loader.load()\n",
    "        print(\"Converting Markdown to text...\")\n",
    "        md_text = converted.convert(md_filepath)\n",
    "\n",
    "        print(\"Remove headers and footers\")\n",
    "        md_text_cleaned = remove_headers_footers(md_text)\n",
    "\n",
    "        md_text_cleaned.document.save_as_markdown(cleaned_md_filepath)\n",
    "        print(\n",
    "            f\"Parsed and cleaned document saved as markdown to: {cleaned_md_filepath}\"\n",
    "        )\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        print(f\"Parsing and cleaning done. Time elapsed: {end_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "# visual check of removed items\n",
    "# TODO make as document_cleaning function: print removed items with largest number of chars first\n",
    "# ## NOTE. high number of chars == more pontetially actual text body\n",
    "\n",
    "# text_items_removed = sorted(text_items_to_drop_visualization, key=lambda x: -x[0])\n",
    "# for i in text_items_removed[:50]:\n",
    "#     print(i) # -->  also subsection titles were removed partly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_file.document.__dict__\n",
    "conv_file.model_dump()\n",
    "## --> references, header and footers are stored as DocItemLabels either as .TEXT (footer,header), .LIST_ITEM  (references) or PAGE_HEADER (header first page)\n",
    "\n",
    "# conv_file.document.model_json_schema()[\"properties\"]#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "#### test docling in langchain \n",
    "TODO : check also docling examples with langchain (see, mindfiretechnology pages):\n",
    "* https://docs.langchain.com/oss/python/integrations/document_loaders/docling\n",
    "* https://docling-project.github.io/docling/examples/rag_langchain/?query=langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE download first related english (transformer, \"_trf\") pipeline trained on web text that includes vocabulary, syntac and entities:\n",
    "# !uv run python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### simple NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a-buch/Documents/TUB_DWN/_PROJECTS/CI-impacts-information-retrieval/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-27 11:16:45,383 - INFO - Going to convert document batch...\n",
      "2025-11-27 11:16:45,384 - INFO - Initializing pipeline for SimplePipeline with options hash 4cc01982ae99b46a2a63fcda46c47c35\n",
      "2025-11-27 11:16:45,384 - INFO - Processing document Koks et al 2022 Brief communication_cleaned.md\n",
      "2025-11-27 11:16:45,427 - INFO - Finished converting document Koks et al 2022 Brief communication_cleaned.md in 0.05 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk text [0]: Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022 https://doi.org/10.5194/nhess-22-3831-2022 © Author(s) 2022. This work is distributed under the Creative Commons Attribution 4.0 License.\n",
      "Brief communication: Critical infrastructure impacts of the 2021 mid-July western European ﬂood event\n",
      "Elco E. Koks1,2, Kees C. H. van Ginkel3,1, Margreet J. E. van Marle3, and Anne Lemnitzer4 1Institute for Environmental Studies, Vrije Universiteit Amsterdam, the Netherlands 2Oxford Programme for Sustainable Infrastructure Systems, Environmental Change Institute, University of Oxford, Oxford, United Kingdom 3Deltares, Delft, the Netherlands 4University of California, Irvine, Irvine, California, United States of America\n",
      "Correspondence: Kees C. H. van Ginkel (kees.vanginkel@deltares.nl)\n",
      "Received: 17 December 2021 – Discussion started: 23 December 2021 Revised: 10 August 2022 – Accepted: 18 October 2022 – Published: 29 November 2022\n",
      "Geospatial Entities in chunk: 9\n",
      "{('Delft', 'GPE'), ('United Kingdom', 'GPE'), ('California', 'GPE'), ('United States of America', 'GPE'), ('the Netherlands', 'GPE'), ('Irvine', 'GPE'), ('Oxford', 'GPE')} \n",
      "\n",
      " chunk text [1]: Abstract. Germany, Belgium and the Netherlands were hit by extreme precipitation and ﬂooding in July 2021. This brief communication provides an overview of the impacts to large-scale critical infrastructure systems and how recovery has progressed. The results show that Germany and Belgium were particularly affected, with many infrastructure assets severely damaged or completely destroyed. Impacts range from completely destroyed bridges and sewage systems, to severely damaged schools and hospitals. We ﬁnd that (large- scale) risk assessments, often focused on larger (river) ﬂood events, do not ﬁnd these local, but severe, impacts due to crit- ical infrastructure failures. This may be the result of limited availability of validation material. As such, this brief com- munication not only will help to better understand how criti- cal infrastructure can be affected by ﬂooding, but also can be used as validation material for future ﬂood risk assessments.\n",
      "Geospatial Entities in chunk: 5\n",
      "{('Netherlands', 'GPE'), ('Belgium', 'GPE'), ('Germany', 'GPE')} \n",
      "\n",
      " chunk text [2]: In mid-July 2021, a persistent low-pressure system caused extreme precipitation in parts of the Belgian, German and Dutch catchments of the Meuse and Rhine rivers. This led to record-breaking water levels and severe ﬂooding (Mohr et al., 2022). Comparable heavy precipitation events in this area have never been registered in most of the affected areas before (Kreienkamp et al., 2021). The German states most af- fected include Rhineland-Palatinate (Rheinland-Pfalz), with damage to the Ahr River valley (Ahrtal), several regions in\n",
      "Geospatial Entities in chunk: 6\n",
      "{('Ahr River', 'LOC'), ('Ahrtal', 'LOC'), ('Rhineland-Palatinate', 'GPE'), ('Rheinland-Pfalz', 'GPE'), ('Meuse', 'LOC'), ('Rhine', 'LOC')} \n",
      "\n",
      " chunk text [3]: the Eiffel National Park, to the city of Trier. Flooding in Belgium was concentrated in the Vesdre River valley (dis- tricts of Pepinster, Ensival and Verviers), the Meuse River valley (Maaseik, Liége), the Gete River valley (Herk-de-Stad and Halen) and southeast Brussels (Wavre). The Netherlands experienced ﬂooding, mostly concentrated in the southern district of Limburg. In total, at least 220 casualties have been reported, with insured loss estimates of approximately EUR 150 million–EUR 250 million in the Netherlands (Ver- bond voor Verzekeraars, 2022), ∼ EUR 2.2 billion in Bel- gium (Assuralia, 2022) and ∼ EUR 8.2 billion (GDV, 2022) in Germany. The event caused major damages to residential and commercial structures and to many critical infrastruc- ture (CI) assets. Not only vital functions for ﬁrst responders were affected (e.g. hospitals, ﬁre departments), but also rail- ways, bridges and utility networks (e.g. water and electricity\n",
      "Geospatial Entities in chunk: 19\n",
      "{('the Gete River valley', 'LOC'), ('the Vesdre River valley', 'LOC'), ('Verviers', 'GPE'), ('Pepinster', 'GPE'), ('Halen', 'GPE'), ('Wavre', 'GPE'), ('Trier', 'GPE'), ('Netherlands', 'GPE'), ('Herk-de-', 'LOC'), ('Maaseik', 'LOC'), ('Liége', 'GPE'), ('Brussels', 'GPE'), ('Germany', 'GPE'), ('Ensival', 'GPE'), ('Limburg', 'GPE'), ('Belgium', 'GPE'), ('the Eiffel National Park', 'FAC'), ('the Meuse River valley', 'LOC')} \n",
      "\n",
      " chunk text [4]: supply) were severely damaged, expecting to take months to years to fully rebuild.\n",
      "CI is often considered to be the backbone of a well- functioning society (Hall et al., 2016), which is particularly eminent during natural hazards and disasters. For instance, failure of electricity or telecommunication services immedi- ately causes disruptions in the day-to-day functioning of peo- ple and businesses, including those outside the directly af- fected area. Despite the (academic) agreement that failure of infrastructure systems may cause (large-scale) societal dis- ruptions (Garschagen and Sandholz, 2018; Hallegatte et al., 2019; Fekete and Sandholz, 2021), empirical evidence on the impacts of extreme weather events on these systems is still\n",
      "Published by Copernicus Publications on behalf of the European Geosciences Union.\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Geospatial Entities in chunk: 0\n",
      "set() \n",
      "\n",
      " chunk text [5]: limited. This brief communication provides an overview of the observed ﬂood impacts to large-scale infrastructure sys- tems during the 2021 mid-July western European ﬂood event and how reconstruction of these large-scale systems has pro- gressed. Next, we highlight how some of these observations compare to academic modelling approaches. We conclude with suggestions on moving forward in CI risk modelling, based on the lessons learned from this extreme event.\n",
      "Geospatial Entities in chunk: 0\n",
      "set() \n",
      "\n",
      " chunk text [6]: In Germany, road and railway infrastructure was severely damaged as documented exemplarily in Fig. 1. Cost esti- mates reach up to EURO 2 billion Euro (MDR, 2021). More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR 100 million (Hauser, 2021). Of the 112 bridges in the ﬂooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the ﬂood event (MDR, 2021). Over 74 km of roads, paths and bridges in the Ahr valley have been (critically) damaged. In some cases, repairs are expected to take months to years (Zeit Online, 2021). For example, ma- jor freeway sections, including parts of the A1 motorway, were closed until early 2022 (24Rhein, 2022). In addition, about 50 000 cars were damaged, causing insurance claims of some EUR 450 million (ADAC, 2021). The German railway provider Deutsche Bahn expects asset damages of around EUR 1.3 billion. Among other things, 180\n",
      "Geospatial Entities in chunk: 7\n",
      "{('MDR', 'GPE'), ('A1', 'FAC'), ('the Ahr valley', 'LOC'), ('Germany', 'GPE'), ('ma- jor', 'LOC'), ('Rhineland-Palatinate', 'GPE')} \n",
      "\n",
      " chunk text [7]: level crossings, almost 40 signal boxes, over 1000 catenary and signal masts, and 600 km of tracks were destroyed, as well as energy sup- ply systems, elevators and lighting systems (MDR, 2021). As of 11 April 2022, 14 of the affected rail stretches are fully functional again. The less damaged stretches were func- tional again within 3 months, while some of the most dam- aged sections in the Ahr valley are expected to be ﬁnished by the end of 2025 (DB, 2022). In Belgium, approximately 10 km of railway tracks and 3000 sleeper tracks have to be re- placed; 50 km of catenary needs to be repaired; and 70 000 t of railway track bed needs to be placed, with estimated costs between EUR 30 million–EUR 50 million (Rozendaal, 2021a). Most damages have been repaired within 2 weeks. The most severely damaged railway line (between the vil- lages of Spa and Pepinster) was reopened again on 3 Octo- ber 2021 (Rozendaal, 2021b). In the Netherlands, no large- scale damage has been reported to transport infrastructure. A few national highways were partly ﬂooded\n",
      "Geospatial Entities in chunk: 5\n",
      "{('the Ahr valley', 'LOC'), ('Spa', 'GPE'), ('Pepinster', 'GPE'), ('Netherlands', 'GPE'), ('Belgium', 'GPE')} \n",
      "\n",
      " chunk text [8]: (e.g. the A76 in both directions) or brieﬂy closed (&lt; 3 d) because of the po- tential of ﬂooding. Most likely due to relative low-ﬂow ve- locities, damage to Dutch national road infrastructure was limited. Several railway sections were closed (e.g. the rail-\n",
      "way section between Maastricht and Liége) and some dam- age occurred to the railway infrastructure, in particular to the electronic “track circuit” devices and saturated railway em- bankments (Prorail, 2021).\n",
      "Geospatial Entities in chunk: 3\n",
      "{('Liége', 'GPE'), ('Maastricht', 'GPE'), ('A76', 'FAC')} \n",
      "\n",
      " chunk text [9]: At the peak of the event, around 200 000 people experienced power outages in Germany. Electricity infrastructure was severely damaged in North Rhine-Westphalia and Rhineland- Palatinate. However, within 2 d around 50 % of the power was restored through repairs and temporary ﬁxes. Within 8 weeks, no emergency power generators were required any- more, with most of the power infrastructure restored in Ger- many’s affected areas. Some areas, however, only had perma- nent power infrastructure after 6 months (Westnetz, 2022). The gas distribution network in the Ahr valley was severely damaged. Approximately 133 km of natural gas pipelines, 8500 gas metres, 3400 house pressure regulators, 7220 of the approximately 8000 household connections, and 31 systems measuring and regulating gas pressure have been damaged or destroyed (SWR, 2021). Gas supply was almost fully re- stored within 4.5 months after the ﬂood event (Energienetze Mittelrhein, 2021). In Belgium, approximately 41 500 peo- ple experienced power outages at the peak of the event. This was the result of both damaged and deliberately switched- off electrical cabinets to prevent serious damages. It took around 3 weeks to fully restore power.\n",
      "Geospatial Entities in chunk: 6\n",
      "{('Westnetz', 'GPE'), ('Rhineland- Palatinate', 'GPE'), ('the Ahr valley', 'LOC'), ('Germany', 'GPE'), ('North Rhine-Westphalia', 'GPE'), ('Belgium', 'GPE')} \n",
      "\n",
      " chunk text [10]: Similar to Germany, severe damage had been observed to the gas network. In the villages around Liége, such as Chaudfontaine and Pepinster (Belgium), gas supply was fully recovered within 5 months (Grosjean, 2021; De Wolf, 2021). In the Netherlands, 1000– 2000 households experienced a loss of electricity supply at the peak of the event. Between 100 to 200 households had no gas supply. Within several days, electricity supply was re- stored (Task Force Fact Finding Hoogwater, 2021).\n",
      "Geospatial Entities in chunk: 7\n",
      "{('Grosjean', 'GPE'), ('Pepinster', 'GPE'), ('Germany', 'GPE'), ('Netherlands', 'GPE'), ('Liége', 'GPE'), ('Belgium', 'GPE'), ('Chaudfontaine', 'GPE')} \n",
      "\n",
      " chunk text [11]: In the region of Rhineland-Palatinate (Germany), most drink- ing water supply was restored within 2 months (Hochwasser Ahr, 2021a). However, sewage treatment plants in Alte- nahr, Mayschoss and Sinzig had been largely destroyed (Hochwasser Ahr, 2021b), and it is expected to take at least 1.5 years to fully repair most sewage treatment plants. Emer- gency sewage treatment plants have been built in the mean- time (GA, 2021). In the Erft region 7 out of 31 wastewater facilities had been destroyed. Many facilities reported pollu- tion of oil and diesel, forming layers up to 15 cm thick (Kuhn, 2021). In addition, much of the groundwater (and soil) in the ﬂood region was mixed with oil (from destroyed residen- tial oil tanks), chemicals such as fertilizers (from wineries and other agriculture) and chemicals from nearby industrial plants. In Sinzig, 3.6 × 106 L of oil–water mixture was re- cycled, gaining 3600 m3 of oil, to be reused for heating and\n",
      "Geospatial Entities in chunk: 10\n",
      "{('Mayschoss', 'GPE'), ('Sinzig', 'GPE'), ('Germany', 'GPE'), ('Alte- nahr', 'GPE'), ('Kuhn', 'GPE'), ('Erft', 'GPE'), ('Rhineland-Palatinate', 'GPE'), ('Hochwasser Ahr', 'GPE')} \n",
      "\n",
      " chunk text [12]: Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Figure 1. Damage in the Ahr valley, Germany (images taken on 11 August 2021). (a) Destruction of federal highway B266 (A1) and railway (A2) near Heimersheim. (b) Further upstream in the Ahr valley (Altenburg), large stretches of the Ahrtalbahn railway have been destroyed (B1) and the few remaining road and rail bridges show signs of temporary repairs (B2). (c) Riverbed erosion uncovered and destroyed many cables supposed to lie more than 80 cm below surface level (C1) as well as sewers (C2). (d) Inundated electricity dis- tribution infrastructure (D1), road erosion and stabilization (D2), uncovered cables (D3), and collapsed buildings in Schuld. Pictures by Margreet van Marle/Deltares/GEERassociation, distributed under Creative Commons Attribution 4.0 license.\n",
      "Geospatial Entities in chunk: 9\n",
      "{('Ahrtalbahn railway', 'FAC'), ('the Ahr valley', 'LOC'), ('Heimersheim', 'GPE'), ('Germany', 'GPE'), ('A2', 'FAC'), ('B266', 'FAC'), ('Altenburg', 'GPE'), ('Schuld', 'GPE')} \n",
      "\n",
      " chunk text [13]: industrial usage (Kuhn, 2021). In the heavily destroyed town of Bad Münstereifel (in the state of North Rhine-Westphalia), drinking water supply was re-established within 5 d after the ﬂood event (most frequently through emergency tanks), and about 50 % of the city centre was reconnected to the fresh- water network shortly thereafter however, water had to be boiled before consumption until about 1 month later (Bad Münstereifel, 2021). In Belgium, several towns experienced disruptions in water supply (in particular as a result of pol- lution). Directly after the event, approximately 3400 families had no access to potable water. Within less than a week, this was reduced to around 1650 families (Terzake, 2021). It took, however, 6 months to rebuild the permanent water supply in- frastructure (SWDE, 2022). In the Netherlands, little to no problems have been recorded with regards to water supply.\n",
      "Geospatial Entities in chunk: 6\n",
      "{('Netherlands', 'GPE'), ('North Rhine-Westphalia', 'GPE'), ('Bad Münstereifel', 'GPE'), ('Kuhn', 'GPE'), ('Belgium', 'GPE')} \n",
      "\n",
      " chunk text [14]: We found no information regarding direct impact on solid- waste facilities as a result of the ﬂood event. However, there is a large pressure on the solid-waste sector to clean the af- fected areas; 1 month after the event, we observed dozens of large temporary waste ﬁlls and frequent incidences of oil pollution in Rhineland-Palatinate during a ﬁeld visit. In the Ahrweiler district alone, the ﬂood caused as much solid waste as normally would be collected over 30 years. In Belgium, the amount of solid waste is estimated around 160 000 t, stored at several places, such as the abandoned highway track A601. This highway has been used for approx- imately 9 months as a temporary storage for debris (Cou- plez, 2022). In the Netherlands, there have been primarily problems with waste deposits along the river banks, which is mostly the solid waste transported by the river from fur- ther upstream. Thousands of tonnes of tree debris (logs and\n",
      "Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Geospatial Entities in chunk: 6\n",
      "{('A601', 'FAC'), ('Cou- plez', 'FAC'), ('Netherlands', 'GPE'), ('Rhineland-Palatinate', 'GPE'), ('Belgium', 'GPE'), ('Ahrweiler', 'LOC')} \n",
      "\n",
      " chunk text [15]: of running water and electricity (Ärzte Zeitung, 2021). Af- ter 1.5 months, medical care was guaranteed again in the most affected regions in Rhineland-Palatinate (Hochwasser Ahr, 2021c). In the state of North Rhine-Westphalia, approx- imately 68 hospitals have been affected, of which several have been affected severely and will take at least 1.5 years to be rebuilt (Fig. 2). Direct damages are estimated to be at least EUR 100 million to repair all medical facilities (Ko- rzilius, 2021). In the town of Eschweiler (Germany), for ex- ample, the basement of the hospital was ﬂooded, as well as the outbuildings and the entire outdoor area. The power sup- ply collapsed, the entire building technology was destroyed and some 300 patients had to be evacuated by helicopter. Property damage is expected to be around EUR 50 million. Within 3.5 weeks, the hospital was partly operational, and within 3 months, all hospital operations continued normally (SAH Eschweiler, 2021). The Mutterhaus Ehrang hospital in Trier (Germany) is now permanently closed as the hospital is too severely damaged to rebuild. Furthermore, in\n",
      "Geospatial Entities in chunk: 8\n",
      "{('Germany', 'GPE'), ('Mutterhaus Ehrang', 'FAC'), ('Trier', 'GPE'), ('Rhineland-Palatinate', 'GPE'), ('North Rhine-Westphalia', 'GPE'), ('Eschweiler', 'GPE'), ('Hochwasser Ahr', 'GPE')} \n",
      "\n",
      " chunk text [16]: the region of Rhineland-Palatinate (Germany), 19 daycare centres and 17 schools suffered damage from the ﬂoods, affecting more than 8000 students (Staib, 2021). Approximately 4 months after the ﬂood event, the district of Bad Neuenahr-Ahrweiler established emergency educational facilities using 297 con- tainers that serve as classrooms, ofﬁces and dining facilities for more than 800 students (Wiesbadener Kurier, 2021). In Belgium, various rural clinics have been affected and were unable to provide any services. Concurrently, in the most af- fected areas, general-practitioner facilities have been com- pletely destroyed (Le Spécialiste, 2021). In the Netherlands, one nursing home was ﬂooded, and one hospital was evacu- ated as a precautionary measure.\n",
      "Geospatial Entities in chunk: 5\n",
      "{('Germany', 'GPE'), ('Bad Neuenahr-Ahrweiler', 'GPE'), ('Netherlands', 'GPE'), ('Rhineland-Palatinate', 'GPE'), ('Belgium', 'GPE')} \n",
      "\n",
      " chunk text [17]: Most often, large-scale object-based infrastructure impact studies (e.g. Bubeck et al., 2019) only disclose aggregated risk metrics (i.e. country-level risk estimates), which ham- pers veriﬁcation and validation with observed impacts on smaller scales. Van Ginkel et al. (2021) assessed river ﬂood risk for all road segments in Europe. Of the eight motorway ﬂoods incidents in Germany reported by Hauser (2021), three are recognizable as ﬂood hotspots in van Ginkel et al. (2021). During the event in 2021, most damage was caused by rel- atively small rivers which are only represented in the haz- ard data from the point that the upstream catchment is above 500 km2. For example, the Ahr valley is partly covered (400 of the 900 km2) by van Ginkel et al., 2021, who estimate the road repair costs at EUR 4 million to EUR 29 million (under low- and high-ﬂow velocities respectively.) for a 1 : 500 year event. The ﬁeld visit showed damage caused by high-ﬂow velocities at multiple places, and video footage of\n",
      "Geospatial Entities in chunk: 3\n",
      "{('Europe', 'LOC'), ('the Ahr valley', 'LOC'), ('Germany', 'GPE')} \n",
      "\n",
      " chunk text [18]: the events suggests these are locally more towards 2 m s−1, which van\n",
      "Figure 2. Overview of observed and expected reconstruction dura- tion of each infrastructure sector considered in this study. It should be noted that this ﬁgure presents reconstruction efforts of the sys- tem. No line indicates that no impacts are observed. Solid waste is not included in the ﬁgure, as no impacts were recorded within each country.\n",
      "deadwood) were recycled in the Ahr valley. For instance, the towns of Höenningen and Mayschoss, served as major recy- cle hubs. Per day, approximately 500 t of wood debris was transported, cut, chipped and recycled into ﬁrewood, which continued for at least 6 weeks after the ﬂood (Gather, 2021).\n",
      "Geospatial Entities in chunk: 3\n",
      "{('Mayschoss', 'GPE'), ('the Ahr valley', 'LOC'), ('Höenningen', 'GPE')} \n",
      "\n",
      " chunk text [19]: In Germany, all severely affected areas experienced dis- ruption of mobile network services. Within the region of Rhineland-Palatinate, it took 2 weeks to ensure 100 % cover- age again through emergency communication masts. Within 1 month, most of the network was restored to pre-disaster ser- vice provision. After 5 months, broadband has also been re- stored in the most affected areas, which started in most areas only after power infrastructure was rebuilt (Westnetz, 2021). In Belgium, it has taken around 11 months to restore connec- tion to the last communities within the affected area. In the Netherlands, approximately 7000 households were affected by disrupted telecommunication service. This was primarily due to ﬂooded telecommunication infrastructure in the direct vicinity of ﬂooded houses. However, some distribution cab- inets were ﬂooded as well, with the largest ﬂooded cabinet affecting around 700 households. Due to damaged bridges, several ﬁbre cables were damaged. Five telecommunication masts were affected as well, but “tuning” of the network ensured that the service disruption was kept to a minimum (Task Force Fact Finding Hoogwater, 2021).\n",
      "Geospatial Entities in chunk: 4\n",
      "{('Netherlands', 'GPE'), ('Belgium', 'GPE'), ('Rhineland-Palatinate', 'GPE'), ('Germany', 'GPE')} \n",
      "\n",
      " chunk text [20]: In Germany, an estimated 180 general-practitioner practices have been affected by the ﬂood event. Impacts range from completely destroyed to unable to operate due to a lack\n",
      "Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Ginkel et al. (2021) considered “high-ﬂow velocity”, than towards 0.2 m s−1, which they considered “low-ﬂow veloc- ity”. At ﬁrst sight, the spatial extent of the exposed assets has reasonable correspondence to the model of van Ginkel et al. (2021). However, the model ignores bridge damage, which in reality was a major source of damage (Sect. 2.1). Also, a signiﬁcant share of observed damage resulted from pluvial ﬂooding, ﬂash ﬂooding and landslides which was not captured by van Ginkel et al. (2021).\n",
      "Geospatial Entities in chunk: 1\n",
      "{('Germany', 'GPE')} \n",
      "\n",
      " chunk text [21]: Reconnaissance observations (August 2021) along the rivers Ahr and Erft (Lemnitzer et al., 2022) documented se- vere, as well as irreparable, damage to bridges designed and constructed within the last 2 decades and total destruction of almost all historical bridges, typically constructed on shallow foundations. Historical bridge designs concentrated primar- ily on cross-sectional requirements for expected water vol- umes. Triggered by ﬂood events in the past four decades, bridge design research has broadened by focusing on risk- based scour assessment, hydrodynamic pier designs, reduc- tion of intermediate bridge support elements, impact and col- lision loading, implementation of bridge protection mecha- nisms such as from wood debris, and machine learning ap- proaches from past failures (VAW 188, 2006; Bento et al., 2020; Majtan et al., 2021; Naser, 2021). Accounting for all these mechanisms, however, is complex (Haehnel and Daly, 2004) and no guarantee to avoid the observed failures. Var- ious international design codes (e.g. American bridge stan- dard AASHTO, Australian bridge standard AS5100, and Japanese bridge\n",
      "Geospatial Entities in chunk: 2\n",
      "{('Erft', 'LOC'), ('Ahr', 'LOC')} \n",
      "\n",
      " chunk text [22]: standard SHB) provide quantitative tools to assess impact loading from debris/tree logs; however, bridges erected prior to recent design requirements are unable to maintain global structural stability under the excessive mul- tidirectional loading, such as seen in the 2021 ﬂoods. Based on ﬁeld observations, the advancement of erosion prevention practices for ﬂood events emerged as a critical research fo- cus, as the interface stability between water, soil and foun- dation elements was found to be compromised at almost all bridge damage locations visited.\n",
      "Geospatial Entities in chunk: 0\n",
      "set() \n",
      "\n",
      " chunk text [23]: Next to the above insights into modelling direct physical damages, we can also use the observation from the event to further improve and validate our assumptions on post- disaster (infrastructure) recovery. In particular, when mod- elling the economic and societal impacts, the recovery pro- cess is one of the most important drivers of losses (e.g. Koks et al., 2015). The July 2021 event has given us several in- sights. Firstly, there is a prioritization between different in- frastructure systems. In Germany, for example, we found that in several affected areas the electricity network was repaired ﬁrst, which was subsequently followed by the gas and broad- band network. Secondly, there is a prioritization within in- frastructure systems. For example, more critical roads are re- paired sooner than less critical roads. While this may sound obvious, academic studies often consider a recovery of the entire system, without considering a speciﬁc order of im- portance. Finally, good recovery management practices and\n",
      "enough trades(wo)men (e.g. electricians, utility workers) are one of the most important drivers of a speedy and successful recovery. These are often not included within the modelling assumptions.\n",
      "Geospatial Entities in chunk: 1\n",
      "{('Germany', 'GPE')} \n",
      "\n",
      " chunk text [24]: Based on our ﬁndings, we highlight three aspects to move forward in the ﬁeld of infrastructure disaster risk assess- ments. First, merely focusing on ﬂood extent and depth is not sufﬁcient to estimate the impacts of extreme ﬂood events to infrastructure. In particular, in Germany and Belgium, it became evident that the high discharge and streamﬂow and corresponding high-ﬂow velocities (resulting from the lo- cal topography and the intensity of the rainfall) are a de- cisive factor in explaining the degree of destruction. Many of the observed failures such as bridge scour, road embank- ment instabilities and erosion of aggregate foundations could likely better be explained from ﬂow velocity rather than ﬂood depth. Future ﬂood impact studies, especially those focusing on transport infrastructure, should aim to account for ﬂow velocity in their impact modelling, in particular in areas with steep gradients.\n",
      "Geospatial Entities in chunk: 2\n",
      "{('Belgium', 'GPE'), ('Germany', 'GPE')} \n",
      "\n",
      " chunk text [25]: Second, the observed impacts on CI highlight the inﬂu- ence of spatial scale on the magnitude of the impacts. On a local and regional level, the disruptions in daily lives and to the economy were enormous. Yet, zoomed out on a national scale, the impacts were relatively small. While large-scale studies are useful to identify potential hotspots and bottle- necks in the system, local-scale studies are essential to better understand the real impacts (and are also better able to do so). This is true for both the consequences to infrastructure assets and the services and the impacts on lives and livelihoods.\n",
      "Geospatial Entities in chunk: 0\n",
      "set() \n",
      "\n",
      " chunk text [26]: Finally, the level of destruction and disruption caused by this event highlights the need for the development of both asset and system-level adaptation measures, securing more resilient infrastructure systems. Extreme weather events are expected to become more likely not only in western Europe, but also globally in an increasingly warmer world. As such, there is an urgency to investigate not only how service provi- sion can be ensured in the case of an extreme event but also how the recovery process to a minimum service level can be as swift and smooth as possible. This calls for a further collaboration between the different sectors of reliability and systems engineering and disaster risk modelling and manage- ment. The limited number of studies on impact on CI due to ﬂooding highlights the need for more detailed infrastructure failure impact assessments including cascading impacts.\n",
      "Data availability. No data sets were used in this article.\n",
      "Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Geospatial Entities in chunk: 1\n",
      "{('Europe', 'LOC')} \n",
      "\n",
      " chunk text [27]: Author contributions. All authors collaborated and contributed to drafting, reviewing and editing the paper. EEK and KCHvG con- tributed equally to the initial idea of this manuscript. EEK wrote the original draft of the manuscript, with key input from KCHvG. EEK and AL collected the information for Germany and Belgium. KCHvG and MJEvM collected most of the information for the Netherlands. EEK created Fig. 2. KCHvG, MJVEvM and AL par- ticipated in a GEER ﬁeld trip to visit the affected area in the disaster aftermath.\n",
      "Competing interests. The contact author has declared that none of the authors has any competing interests.\n",
      "Disclaimer. Publisher’s note: Copernicus Publications remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations.\n",
      "Financial support. This research has been supported by the Ned- erlandse Organisatie voor Wetenschappelijk Onderzoek (grant no. VI.Veni.194.033) and funded as part of the EU Horizon 2020 project RECEIPT (grant no. 820712).\n",
      "Geospatial Entities in chunk: 3\n",
      "{('Netherlands', 'GPE'), ('Belgium', 'GPE'), ('Germany', 'GPE')} \n",
      "\n",
      " chunk text [28]: Review statement. This paper was edited by Joaquim G. Pinto and reviewed by three anonymous referees.\n",
      "Geospatial Entities in chunk: 0\n",
      "set() \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import spacy\n",
    "from spacy_layout import spaCyLayout\n",
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s\n",
    "\n",
    "\n",
    "PARSED_TEXT_DIR = \"../\" + s.settings.PATH_DATA + \"parsed_documents/\"\n",
    "FILE_PATH = PARSED_TEXT_DIR + \"Koks et al 2022 Brief communication_cleaned.md\"\n",
    "\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "loader = DoclingLoader(FILE_PATH)  # use chunks from Docling.Loader\n",
    "doc = loader.load()\n",
    "\n",
    "\n",
    "# # use chunks defined by Docling (list[Document])\n",
    "# for i, chunk in enumerate(doc):\n",
    "#     nlp_doc = nlp(chunk.page_content)  # apply spacy model for NER on each chunk\n",
    "#     print(f\"\\n {i} chunk text:\", chunk.page_content[:100], \"...\")\n",
    "#     print(f\"Named Entities in chunk: {len(nlp_doc.ents)}\")\n",
    "#     print(f\"{ {(ent.text, ent.label_) for ent in nlp_doc.ents} } \")\n",
    "#     i += 1\n",
    "\n",
    "## show only GEO-entities\n",
    "for i, chunk in enumerate(doc):\n",
    "    nlp_doc = nlp(chunk.page_content)  # apply spacy model for NER on each chunk\n",
    "    print(f\"\\n chunk text [{i}]:\", chunk.page_content)\n",
    "    # select only geospatial entities\n",
    "    geo_ents = [(ent.text, ent.label_) for ent in nlp_doc.ents if ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]]  \n",
    "    print(f\"Geospatial Entities in chunk: {len(geo_ents)}\")\n",
    "    print(f\"{ {(geo_ents[i][0], geo_ents[i][1]) for i in range(len(geo_ents))} } \")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "##### Conclusions from simple geo-entity recognition\n",
    "* missing entity linking to actual CI impacts\n",
    "* from entities and their labels it is not clear if the entity is a river, valley etc (e.g. (Ahr, LOC), (Ehr, LOC)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75fe6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5862b1bc",
   "metadata": {},
   "source": [
    "##### Geo-Entity linking\n",
    "test to extract geo-entity closest to CI impact/ CI type \n",
    "1. create new transport infrastructure entity (CI_TYPE)\n",
    "2. get either geo-entity closest to the respective verb (e.g. \"damaged, destroyed, blocked ..\") or clostest to the respective CI-entity (from step 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:48: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\C'\n",
      "/tmp/ipykernel_2309873/1950560377.py:48: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  print(f\"\\Chunk text [{i}]:\", chunk.page_content)\n",
      "2025-11-28 00:30:01,381 - INFO - Going to convert document batch...\n",
      "2025-11-28 00:30:01,382 - INFO - Initializing pipeline for SimplePipeline with options hash 4cc01982ae99b46a2a63fcda46c47c35\n",
      "2025-11-28 00:30:01,382 - INFO - Processing document Koks et al 2022 Brief communication_cleaned.md\n",
      "2025-11-28 00:30:01,516 - INFO - Finished converting document Koks et al 2022 Brief communication_cleaned.md in 0.14 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of CI_TYPE entities in chunk [1]: 1\n",
      "\\Chunk text [1]: Abstract. Germany, Belgium and the Netherlands were hit by extreme precipitation and ﬂooding in July 2021. This brief communication provides an overview of the impacts to large-scale critical infrastructure systems and how recovery has progressed. The results show that Germany and Belgium were particularly affected, with many infrastructure assets severely damaged or completely destroyed. Impacts range from completely destroyed bridges and sewage systems, to severely damaged schools and hospitals. We ﬁnd that (large- scale) risk assessments, often focused on larger (river) ﬂood events, do not ﬁnd these local, but severe, impacts due to crit- ical infrastructure failures. This may be the result of limited availability of validation material. As such, this brief com- munication not only will help to better understand how criti- cal infrastructure can be affected by ﬂooding, but also can be used as validation material for future ﬂood risk assessments.\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Belgium\" at distance 1\n",
      "\n",
      "Number of CI_TYPE entities in chunk [3]: 1\n",
      "\\Chunk text [3]: the Eiffel National Park, to the city of Trier. Flooding in Belgium was concentrated in the Vesdre River valley (dis- tricts of Pepinster, Ensival and Verviers), the Meuse River valley (Maaseik, Liége), the Gete River valley (Herk-de-Stad and Halen) and southeast Brussels (Wavre). The Netherlands experienced ﬂooding, mostly concentrated in the southern district of Limburg. In total, at least 220 casualties have been reported, with insured loss estimates of approximately EUR 150 million–EUR 250 million in the Netherlands (Ver- bond voor Verzekeraars, 2022), ∼ EUR 2.2 billion in Bel- gium (Assuralia, 2022) and ∼ EUR 8.2 billion (GDV, 2022) in Germany. The event caused major damages to residential and commercial structures and to many critical infrastruc- ture (CI) assets. Not only vital functions for ﬁrst responders were affected (e.g. hospitals, ﬁre departments), but also rail- ways, bridges and utility networks (e.g. water and electricity\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Germany\" at distance 1\n",
      "\n",
      "Number of CI_TYPE entities in chunk [6]: 9\n",
      "\\Chunk text [6]: In Germany, road and railway infrastructure was severely damaged as documented exemplarily in Fig. 1. Cost esti- mates reach up to EURO 2 billion Euro (MDR, 2021). More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR 100 million (Hauser, 2021). Of the 112 bridges in the ﬂooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the ﬂood event (MDR, 2021). Over 74 km of roads, paths and bridges in the Ahr valley have been (critically) damaged. In some cases, repairs are expected to take months to years (Zeit Online, 2021). For example, ma- jor freeway sections, including parts of the A1 motorway, were closed until early 2022 (24Rhein, 2022). In addition, about 50 000 cars were damaged, causing insurance claims of some EUR 450 million (ADAC, 2021). The German railway provider Deutsche Bahn expects asset damages of around EUR 1.3 billion. Among other things, 180\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"Germany\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Germany\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"motorways\" is \"Germany\" at distance 8\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"the Ahr valley\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Rhineland-Palatinate\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"roads\" is \"the Ahr valley\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"the Ahr valley\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"motorway\" is \"ma- jor\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"ma- jor\" at distance 11\n",
      "\n",
      "Number of CI_TYPE entities in chunk [7]: 4\n",
      "\\Chunk text [7]: level crossings, almost 40 signal boxes, over 1000 catenary and signal masts, and 600 km of tracks were destroyed, as well as energy sup- ply systems, elevators and lighting systems (MDR, 2021). As of 11 April 2022, 14 of the affected rail stretches are fully functional again. The less damaged stretches were func- tional again within 3 months, while some of the most dam- aged sections in the Ahr valley are expected to be ﬁnished by the end of 2025 (DB, 2022). In Belgium, approximately 10 km of railway tracks and 3000 sleeper tracks have to be re- placed; 50 km of catenary needs to be repaired; and 70 000 t of railway track bed needs to be placed, with estimated costs between EUR 30 million–EUR 50 million (Rozendaal, 2021a). Most damages have been repaired within 2 weeks. The most severely damaged railway line (between the vil- lages of Spa and Pepinster) was reopened again on 3 Octo- ber 2021 (Rozendaal, 2021b). In the Netherlands, no large- scale damage has been reported to transport infrastructure. A few national highways were partly ﬂooded\n",
      "  Closest GEO entity to CI_TYPE entity \"rail\" is \"the Ahr valley\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Belgium\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Belgium\" at distance 6\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Spa\" at distance 1\n",
      "\n",
      "Number of CI_TYPE entities in chunk [8]: 4\n",
      "\\Chunk text [8]: (e.g. the A76 in both directions) or brieﬂy closed (&lt; 3 d) because of the po- tential of ﬂooding. Most likely due to relative low-ﬂow ve- locities, damage to Dutch national road infrastructure was limited. Several railway sections were closed (e.g. the rail-\n",
      "way section between Maastricht and Liége) and some dam- age occurred to the railway infrastructure, in particular to the electronic “track circuit” devices and saturated railway em- bankments (Prorail, 2021).\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"Maastricht\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Maastricht\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Liége\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Liége\" at distance 2\n",
      "\n",
      "Number of CI_TYPE entities in chunk [12]: 5\n",
      "\\Chunk text [12]: Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Figure 1. Damage in the Ahr valley, Germany (images taken on 11 August 2021). (a) Destruction of federal highway B266 (A1) and railway (A2) near Heimersheim. (b) Further upstream in the Ahr valley (Altenburg), large stretches of the Ahrtalbahn railway have been destroyed (B1) and the few remaining road and rail bridges show signs of temporary repairs (B2). (c) Riverbed erosion uncovered and destroyed many cables supposed to lie more than 80 cm below surface level (C1) as well as sewers (C2). (d) Inundated electricity dis- tribution infrastructure (D1), road erosion and stabilization (D2), uncovered cables (D3), and collapsed buildings in Schuld. Pictures by Margreet van Marle/Deltares/GEERassociation, distributed under Creative Commons Attribution 4.0 license.\n",
      "  Closest GEO entity to CI_TYPE entity \"railway\" is \"Heimersheim\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"Altenburg\" at distance 2\n",
      "  Closest GEO entity to CI_TYPE entity \"rail\" is \"Altenburg\" at distance 3\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Schuld\" at distance 3\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"Schuld\" at distance 1\n",
      "\n",
      "Number of CI_TYPE entities in chunk [17]: 3\n",
      "\\Chunk text [17]: Most often, large-scale object-based infrastructure impact studies (e.g. Bubeck et al., 2019) only disclose aggregated risk metrics (i.e. country-level risk estimates), which ham- pers veriﬁcation and validation with observed impacts on smaller scales. Van Ginkel et al. (2021) assessed river ﬂood risk for all road segments in Europe. Of the eight motorway ﬂoods incidents in Germany reported by Hauser (2021), three are recognizable as ﬂood hotspots in van Ginkel et al. (2021). During the event in 2021, most damage was caused by rel- atively small rivers which are only represented in the haz- ard data from the point that the upstream catchment is above 500 km2. For example, the Ahr valley is partly covered (400 of the 900 km2) by van Ginkel et al., 2021, who estimate the road repair costs at EUR 4 million to EUR 29 million (under low- and high-ﬂow velocities respectively.) for a 1 : 500 year event. The ﬁeld visit showed damage caused by high-ﬂow velocities at multiple places, and video footage of\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"Europe\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"motorway\" is \"Germany\" at distance 1\n",
      "  Closest GEO entity to CI_TYPE entity \"road\" is \"the Ahr valley\" at distance 4\n",
      "\n",
      "Number of CI_TYPE entities in chunk [19]: 1\n",
      "\\Chunk text [19]: In Germany, all severely affected areas experienced dis- ruption of mobile network services. Within the region of Rhineland-Palatinate, it took 2 weeks to ensure 100 % cover- age again through emergency communication masts. Within 1 month, most of the network was restored to pre-disaster ser- vice provision. After 5 months, broadband has also been re- stored in the most affected areas, which started in most areas only after power infrastructure was rebuilt (Westnetz, 2021). In Belgium, it has taken around 11 months to restore connec- tion to the last communities within the affected area. In the Netherlands, approximately 7000 households were affected by disrupted telecommunication service. This was primarily due to ﬂooded telecommunication infrastructure in the direct vicinity of ﬂooded houses. However, some distribution cab- inets were ﬂooded as well, with the largest ﬂooded cabinet affecting around 700 households. Due to damaged bridges, several ﬁbre cables were damaged. Five telecommunication masts were affected as well, but “tuning” of the network ensured that the service disruption was kept to a minimum (Task Force Fact Finding Hoogwater, 2021).\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Netherlands\" at distance 3\n",
      "\n",
      "Number of CI_TYPE entities in chunk [20]: 1\n",
      "\\Chunk text [20]: In Germany, an estimated 180 general-practitioner practices have been affected by the ﬂood event. Impacts range from completely destroyed to unable to operate due to a lack\n",
      "Nat. Hazards Earth Syst. Sci., 22, 3831–3838, 2022\n",
      "E. E. Koks et al.: Flood impacts to infrastructure\n",
      "Ginkel et al. (2021) considered “high-ﬂow velocity”, than towards 0.2 m s−1, which they considered “low-ﬂow veloc- ity”. At ﬁrst sight, the spatial extent of the exposed assets has reasonable correspondence to the model of van Ginkel et al. (2021). However, the model ignores bridge damage, which in reality was a major source of damage (Sect. 2.1). Also, a signiﬁcant share of observed damage resulted from pluvial ﬂooding, ﬂash ﬂooding and landslides which was not captured by van Ginkel et al. (2021).\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Germany\" at distance 12\n",
      "\n",
      "Number of CI_TYPE entities in chunk [21]: 9\n",
      "\\Chunk text [21]: Reconnaissance observations (August 2021) along the rivers Ahr and Erft (Lemnitzer et al., 2022) documented se- vere, as well as irreparable, damage to bridges designed and constructed within the last 2 decades and total destruction of almost all historical bridges, typically constructed on shallow foundations. Historical bridge designs concentrated primar- ily on cross-sectional requirements for expected water vol- umes. Triggered by ﬂood events in the past four decades, bridge design research has broadened by focusing on risk- based scour assessment, hydrodynamic pier designs, reduc- tion of intermediate bridge support elements, impact and col- lision loading, implementation of bridge protection mecha- nisms such as from wood debris, and machine learning ap- proaches from past failures (VAW 188, 2006; Bento et al., 2020; Majtan et al., 2021; Naser, 2021). Accounting for all these mechanisms, however, is complex (Haehnel and Daly, 2004) and no guarantee to avoid the observed failures. Var- ious international design codes (e.g. American bridge stan- dard AASHTO, Australian bridge standard AS5100, and Japanese bridge\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Erft\" at distance 4\n",
      "  Closest GEO entity to CI_TYPE entity \"bridges\" is \"Erft\" at distance 6\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 7\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 9\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 10\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 11\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 24\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 26\n",
      "  Closest GEO entity to CI_TYPE entity \"bridge\" is \"Erft\" at distance 29\n",
      "\n",
      "Number of CI_TYPE entities in chunk [22]: 2\n",
      "\\Chunk text [22]: standard SHB) provide quantitative tools to assess impact loading from debris/tree logs; however, bridges erected prior to recent design requirements are unable to maintain global structural stability under the excessive mul- tidirectional loading, such as seen in the 2021 ﬂoods. Based on ﬁeld observations, the advancement of erosion prevention practices for ﬂood events emerged as a critical research fo- cus, as the interface stability between water, soil and foun- dation elements was found to be compromised at almost all bridge damage locations visited.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2309873/1950560377.py:48: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  print(f\"\\Chunk text [{i}]:\", chunk.page_content)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[236]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     74\u001b[39m                 \u001b[38;5;66;03m# print(\"\\nidx_in_chunk, closest pair idx\", idx_in_chunk, closest_pair_idx)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m  Closest GEO entity to CI_TYPE entity \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_ents[ci_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_ents[\u001b[43midx_in_chunk\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclosest_pair_idx\u001b[49m\u001b[43m]\u001b[49m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m at distance \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_list[closest_pair_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     78\u001b[39m         \u001b[38;5;66;03m# spacy.displacy.render(\u001b[39;00m\n\u001b[32m     79\u001b[39m         \u001b[38;5;66;03m#     nlp_chunk, style=\"ent\", \u001b[39;00m\n\u001b[32m     80\u001b[39m         \u001b[38;5;66;03m#     options={\"ents\": [\"CI_TYPE\", \"GPE\", \"LOC\", \"FAC\"], \"colors\": {\"CI_TYPE\": \"violet\"}}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# print([(ent.text, ent.label_) for ent in doc_koks.ents])\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m## print([(span.text, span.label_) for span in doc_koks.spans[\"ruler\"]])\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Create New entity for transport infrastructure and apply it on any doc\n",
    " \n",
    "## see for more info: https://spacy.io/usage/rule-based-matching#entityruler\n",
    "## NOTE EntityRuler is hidden inside pipeline\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from langchain_docling import DoclingLoader\n",
    "import spacy\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s\n",
    "\n",
    "\n",
    "## call nlp model and create pipeline with new entity pattern Passed to ruler\n",
    "nlp = spacy.load(\"en_core_web_trf\") \n",
    "config = {\"spans_key\": None, \"annotate_ents\": True, \"overwrite\": False}\n",
    "ruler = nlp.add_pipe(\"span_ruler\", config=config)\n",
    "ruler.add_patterns([   ## TODO pass patterns via jsonl file\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"road\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"roads\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"motorway\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"motorways\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"railway\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"rail\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"bridge\"},\n",
    "    {\"label\": \"CI_TYPE\", \"pattern\": \"bridges\"}\n",
    "])\n",
    "\n",
    "## load doc\n",
    "PARSED_TEXT_DIR = \"../\" + s.settings.PATH_DATA + \"parsed_documents/\"\n",
    "FILE_PATH = PARSED_TEXT_DIR + \"Koks et al 2022 Brief communication_cleaned.md\"\n",
    "loader = DoclingLoader(FILE_PATH)  # use chunks from Docling.Loader\n",
    "doc = loader.load()\n",
    "\n",
    "# TODO FAC make as CI_TYPE: Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "## get most likely geolocation for each CI entity based on distance\n",
    "for i, chunk in enumerate(doc):\n",
    "\n",
    "    nlp_chunk = nlp(chunk.page_content)\n",
    "    all_ents = [ent for ent in nlp_chunk.ents]\n",
    "    ci_type_ents = [ent for ent in nlp_chunk.ents if ent.label_ in [\"CI_TYPE\"]]  \n",
    "            \n",
    "    # check if chunk contains CI_TYPE entities\n",
    "    if len(ci_type_ents)>0:\n",
    "        print(f\"\\nNumber of CI_TYPE entities in chunk [{i}]: {len(ci_type_ents)}\")\n",
    "        print(f\"\\Chunk text [{i}]:\", chunk.page_content)\n",
    "        # print(f\"{ {(ci_type_ents[i].text, ci_type_ents[i].label_) for i in range(len(ci_type_ents))} } \")\n",
    "\n",
    "        # iterate over all entities within chunk\n",
    "        for ent_idx in range(len(all_ents)): \n",
    "\n",
    "            # when entity is CI_TYPE do following ...\n",
    "            if all_ents[ent_idx].label_ == 'CI_TYPE':\n",
    "                ci_idx = ent_idx\n",
    "\n",
    "                ## .. calculate distances between CI_TYPE entity and GEO entities based on index position\n",
    "                distance_list = []\n",
    "                idx_in_chunk = []\n",
    "\n",
    "                try:\n",
    "                    for ent_idx in range(len(all_ents)):\n",
    "                        # TODO make FAC as CI_TYPE as it refers to: Buildings, airports, highways, bridges, etc.\n",
    "                        # TODO calc distances between CI_TYPE ~ GEO entities based on word numbers and not entities\n",
    "                        if all_ents[ent_idx].label_ in ['GPE', 'LOC']: \n",
    "                            geo_idx = ent_idx\n",
    "                            dist_ent_pair = np.abs(ci_idx - geo_idx)\n",
    "                            distance_list.append(dist_ent_pair)\n",
    "                            idx_in_chunk.append((ent_idx))\n",
    "                            closest_pair_idx = np.argmin(distance_list) # idx of closest GEO entity\n",
    "                except ValueError:\n",
    "                    print(\"No GEO entities found.\")\n",
    "                    continue\n",
    "                # print(\"\\nidx_in_chunk, closest pair idx\", idx_in_chunk, closest_pair_idx)\n",
    "                print(f\"\"\"  Closest GEO entity to CI_TYPE entity \"{all_ents[ci_idx]}\" is \"{all_ents[idx_in_chunk[closest_pair_idx]]}\" at distance {distance_list[closest_pair_idx]}\"\"\")\n",
    "                \n",
    "                # spacy.displacy.render(\n",
    "                #     nlp_chunk, style=\"ent\", \n",
    "                #     options={\"ents\": [\"CI_TYPE\", \"GPE\", \"LOC\", \"FAC\"], \"colors\": {\"CI_TYPE\": \"violet\"}}\n",
    "                # )\n",
    "\n",
    "\n",
    "\n",
    "## when apply for entire doc\n",
    "# with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    # doc_koks = f.read()\n",
    "# doc_koks = nlp(doc_koks)  # apply spacy model for NER on each chunk\n",
    "# print([(ent.text, ent.label_) for ent in doc_koks.ents])\n",
    "## print([(span.text, span.label_) for span in doc_koks.spans[\"ruler\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fc69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure 1. Damage in the Ahr valley, Germany (images taken on 11 August 2021).\n",
    "#  (a) Destruction of federal highway B266 (A1) and railway (A2) near Heimersheim. \n",
    "# (b) Further upstream in the Ahr valley (Altenburg), large stretches of the Ahrtalbahn railway have been destroyed \n",
    "# (B1) and the few remaining road and rail bridges show signs of temporary repairs (B2). \n",
    "# (c) Riverbed erosion uncovered and destroyed many cables supposed to lie more than 80 cm below surface level \n",
    "# (C1) as well as sewers (C2). (d) Inundated electricity dis- tribution infrastructure (D1), road erosion and stabilization \n",
    "# (D2), uncovered cables (D3), and collapsed buildings in Schuld. Pictures by Margreet van Marle/Deltares/GEERassociation, distributed under Creative Commons Attribution 4.0 license.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f944691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Germany, road and railway infrastructure was severely damaged as documented exemplarily in Fig. 1. Cost esti- mates reach up to EURO 2 billion Euro (MDR, 2021). More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR 100 million (Hauser, 2021). Of the 112 bridges in the ﬂooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the ﬂood event (MDR, 2021). Over 74 km of roads, paths and bridges in the Ahr valley have been (critically) damaged. In some cases, repairs are expected to take months to years (Zeit Online, 2021). For example, ma- jor freeway sections, including parts of the A1 motorway, were closed until early 2022 (24Rhein, 2022). In addition, about 50 000 cars were damaged, causing insurance claims of some EUR 450 million (ADAC, 2021). The German railway provider Deutsche Bahn expects asset damages of around EUR 1.3 billion. Among other things, 180 \n",
      "\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 0\n",
      "  Closest GEO entity to CI_TYPE entity ('road', 'CI_TYPE') is ('Germany', 'GPE') at distance 1\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 0\n",
      "  Closest GEO entity to CI_TYPE entity ('railway', 'CI_TYPE') is ('Germany', 'GPE') at distance 2\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 1\n",
      "  Closest GEO entity to CI_TYPE entity ('bridges', 'CI_TYPE') is ('the Ahr valley', 'LOC') at distance 2\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 2\n",
      "  Closest GEO entity to CI_TYPE entity ('bridges', 'CI_TYPE') is ('Rhineland-Palatinate', 'GPE') at distance 2\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 4\n",
      "  Closest GEO entity to CI_TYPE entity ('roads', 'CI_TYPE') is ('the Ahr valley', 'LOC') at distance 2\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 4\n",
      "  Closest GEO entity to CI_TYPE entity ('bridges', 'CI_TYPE') is ('the Ahr valley', 'LOC') at distance 1\n",
      "\n",
      "abs_position_in_chunk_list, closest pair idx [0, 16, 17, 23, 28, 32, 33] 6\n",
      "  Closest GEO entity to CI_TYPE entity ('railway', 'CI_TYPE') is ('A1', 'FAC') at distance 9\n"
     ]
    }
   ],
   "source": [
    "tst = [('Germany', 'GPE'), ('road', 'CI_TYPE'), ('railway', 'CI_TYPE'), ('1', 'CARDINAL'), ('EURO 2 billion Euro', 'MONEY'), ('MDR', 'ORG'), ('2021', 'DATE'), ('More than 130 km', 'QUANTITY'), ('50 km', 'QUANTITY'),\n",
    "   ('two months later', 'DATE'), ('EUR 100 million', 'MONEY'), ('Hauser', 'ORG'), ('2021', 'DATE'), ('112', 'CARDINAL'), ('bridges', 'CI_TYPE'), ('40 km', 'QUANTITY'), ('the Ahr valley', 'LOC'),\n",
    " ('Rhineland-Palatinate', 'GPE'), ('62', 'CARDINAL'), ('bridges', 'CI_TYPE'), ('13', 'CARDINAL'),('only 35', 'CARDINAL'),('a month', 'DATE'), ('MDR', 'GPE'), ('2021', 'DATE'), ('74 km', 'QUANTITY'), ('roads', 'CI_TYPE'), ('bridges', 'CI_TYPE'), ('the Ahr valley', 'LOC'), ('months to years', 'DATE'), ('Zeit Online', 'ORG'), ('2021', 'DATE'), ('ma- jor', 'LOC'), ('A1', 'FAC'), ('early 2022', 'DATE'), ('24Rhein', 'ORG'), ('2022', 'DATE'),\n",
    " ('about 50 000', 'CARDINAL'), ('some EUR 450 million', 'MONEY'), ('ADAC', 'ORG'), ('2021', 'DATE'), ('German', 'NORP'), ('railway', 'CI_TYPE'), ('Deutsche Bahn', 'ORG'), ('around EUR 1.3 billion', 'MONEY'), ('180', 'CARDINAL')]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(nlp(doc[6].page_content), \"\\n\")\n",
    "\n",
    "for ci_idx in range(len(tst)):\n",
    "    ## find position of next CI_TYPE entity\n",
    "    if tst[ci_idx][1] == 'CI_TYPE':\n",
    "        \n",
    "        ## NOTE Calculate distance between CI_TYPE entity and GEO entities based on index positions of all entities.\")\n",
    "        distance_list = []\n",
    "        abs_position_in_chunk_list = []\n",
    "\n",
    "        ## select only GEO entities and calculate their distance to CI_TYPE entity\n",
    "        for ent_idx in range(len(tst)):\n",
    "            if tst[ent_idx][1] in ['GPE', 'LOC', 'FAC']: # TODO FAC make as CI_TYPE: Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "                geo_idx = ent_idx\n",
    "                dist_ent_pair = np.abs(ci_idx - geo_idx)\n",
    "                distance_list.append(dist_ent_pair)\n",
    "                abs_position_in_chunk_list.append((ent_idx))\n",
    "\n",
    "        closest_ent_pair_idx = np.argmin(distance_list)\n",
    "        print(\"\\nabs_position_in_chunk_list, closest pair idx\", abs_position_in_chunk_list, closest_ent_pair_idx)\n",
    "        print(f\"\"\"  Closest GEO entity to CI_TYPE entity {tst[ci_idx]} is {tst[abs_position_in_chunk_list[closest_ent_pair_idx]]} at distance {distance_list[closest_ent_pair_idx]}\"\"\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a86e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(pers 1, PERSON), (three, CARDINAL), (loc1, LOC), (pers 2, PERSON), (loc 2 and further loc words, LOC)] \n",
      "\n",
      "['three, CARDINAL), (loc1,']\n",
      "['loc 2 and further loc words,']\n"
     ]
    }
   ],
   "source": [
    "# nlp_doc.ents[i-1]\n",
    "len(nlp_chunk.ents)#[2] \n",
    "# chunk.page_content # \n",
    "\n",
    "#\n",
    "# print([(ent.text, ent.label_) for ent in nlp_chunk.ents], \"\\n\")\n",
    "\n",
    "all_ents_chunk = str(\"[('pers 1', 'PERSON'), ('three', 'CARDINAL'), ('loc1', 'LOC'), ('pers 2', 'PERSON'), ('loc 2 and further loc words', 'LOC')]\")\n",
    "all_ents_chunk = all_ents_chunk.replace(\"'\", \"\")  # lazy cleaning of single quotes\n",
    "print(all_ents_chunk, \"\\n\")\n",
    "\n",
    "# ## use regex to extract text between two entity labels, also for cases of multiple occurence of PERSON and LOC\n",
    "# # #with string.partition(\"PERSON\")[2].partition(\"LOC\")[0] this would not be possible\n",
    "import re\n",
    "\n",
    "# ci_locs = re.findall(r\"(?<='PERSON'\\s).*(?=\\s'LOC')\", all_ents_chunk, flags=re.IGNORECASE)\n",
    "# ci_locs \n",
    "for i in all_ents_chunk.split(\"PERSON\")[1:]:\n",
    "    # print(i)\n",
    "    ci_locs = re.findall(r\"(?<=[(]).*(?=\\sLOC)\", i)\n",
    "\n",
    "    #ci_locs = re.findall(r\"((?:\\S+\\s+){0,1}\\bLOC\\b\\s*(?:\\S+\\b\\s*){0,10})\", i)\n",
    "    # ci_locs = re.findall(r\"LOC'(.*?)((?=,'\\s\\w+')|$)\", i) # look behind\n",
    "    print(ci_locs)\n",
    "# all_ents_chunk.split(\"PERSON\")\n",
    "\n",
    "# # nlp_chunk.ents\n",
    "# #print(f\"{ {(ci_type_ents[i].text, ci_type_ents[i].label_) for i in range(len(ci_type_ents))} } \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab4a7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "spacy.displacy.render(\n",
      "    docs: Union[Iterable[Union[spacy.tokens.doc.Doc, spacy.tokens.span.Span, dict]], spacy.tokens.doc.Doc, spacy.tokens.span.Span, dict],\n",
      "    style: str = \u001b[33m'dep'\u001b[39m,\n",
      "    page: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    minify: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    jupyter: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    options: Dict[str, Any] = {},\n",
      "    manual: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      ") -> str\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Render displaCy visualisation.\n",
      "\n",
      "docs (Union[Iterable[Union[Doc, Span, dict]], Doc, Span, dict]]): Document(s) to visualise.\n",
      "    a 'dict' is only allowed here when 'manual' is set to True\n",
      "style (str): Visualisation style, 'dep' or 'ent'.\n",
      "page (bool): Render markup as full HTML page.\n",
      "minify (bool): Minify HTML markup.\n",
      "jupyter (bool): Override Jupyter auto-detection.\n",
      "options (dict): Visualiser-specific options, e.g. colors.\n",
      "manual (bool): Don't parse `Doc` and instead expect a dict/list of dicts.\n",
      "RETURNS (str): Rendered SVG or HTML markup.\n",
      "\n",
      "DOCS: https://spacy.io/api/top-level#displacy.render\n",
      "USAGE: https://spacy.io/usage/visualizers\n",
      "\u001b[31mFile:\u001b[39m      ~/Documents/TUB_DWN/_PROJECTS/CI-impacts-information-retrieval/.venv/lib/python3.13/site-packages/spacy/displacy/__init__.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "spacy.displacy.render?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:11:37,093 - INFO - Going to convert document batch...\n",
      "2025-11-27 15:11:37,094 - INFO - Initializing pipeline for SimplePipeline with options hash 4cc01982ae99b46a2a63fcda46c47c35\n",
      "2025-11-27 15:11:37,094 - INFO - Processing document Koks et al 2022 Brief communication_cleaned.md\n",
      "2025-11-27 15:11:37,143 - INFO - Finished converting document Koks et al 2022 Brief communication_cleaned.md in 0.05 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk text [6]: In Germany, road and railway infrastructure was severely damaged as documented exemplarily in Fig. 1. Cost esti- mates reach up to EURO 2 billion Euro (MDR, 2021). More than 130 km of motorways were closed directly after the event, of which 50 km were still closed two months later, with an estimated repair cost of EUR 100 million (Hauser, 2021). Of the 112 bridges in the ﬂooded 40 km of the Ahr valley (Rhineland-Palatinate), 62 bridges were destroyed, 13 were severely damaged and only 35 were in operation a month after the ﬂood event (MDR, 2021). Over 74 km of roads, paths and bridges in the Ahr valley have been (critically) damaged. In some cases, repairs are expected to take months to years (Zeit Online, 2021). For example, ma- jor freeway sections, including parts of the A1 motorway, were closed until early 2022 (24Rhein, 2022). In addition, about 50 000 cars were damaged, causing insurance claims of some EUR 450 million (ADAC, 2021). The German railway provider Deutsche Bahn expects asset damages of around EUR 1.3 billion. Among other things, 180\n",
      "Before [('Germany', 3, 10, 'GPE'), ('1', 99, 100, 'CARDINAL'), ('EURO 2 billion Euro', 131, 150, 'MONEY'), ('MDR', 152, 155, 'ORG'), ('2021', 157, 161, 'DATE'), ('More than 130 km', 164, 180, 'QUANTITY'), ('50 km', 241, 246, 'QUANTITY'), ('two months later', 265, 281, 'DATE'), ('EUR 100 million', 316, 331, 'MONEY'), ('Hauser', 333, 339, 'ORG'), ('2021', 341, 345, 'DATE'), ('112', 355, 358, 'CARDINAL'), ('40 km', 381, 386, 'QUANTITY'), ('the Ahr valley', 390, 404, 'LOC'), ('Rhineland-Palatinate', 406, 426, 'GPE'), ('62', 429, 431, 'CARDINAL'), ('13', 456, 458, 'CARDINAL'), ('only 35', 485, 492, 'CARDINAL'), ('a month', 511, 518, 'DATE'), ('MDR', 541, 544, 'GPE'), ('2021', 546, 550, 'DATE'), ('74 km', 558, 563, 'QUANTITY'), ('the Ahr valley', 595, 609, 'LOC'), ('months to years', 686, 701, 'DATE'), ('Zeit Online', 703, 714, 'ORG'), ('2021', 716, 720, 'DATE'), ('ma- jor', 736, 743, 'LOC'), ('A1', 785, 787, 'FAC'), ('early 2022', 816, 826, 'DATE'), ('24Rhein', 828, 835, 'ORG'), ('2022', 837, 841, 'DATE'), ('about 50 000', 857, 869, 'CARDINAL'), ('some EUR 450 million', 917, 937, 'MONEY'), ('ADAC', 939, 943, 'ORG'), ('2021', 945, 949, 'DATE'), ('German', 956, 962, 'NORP'), ('Deutsche Bahn', 980, 993, 'ORG'), ('around EUR 1.3 billion', 1019, 1041, 'MONEY'), ('180', 1063, 1066, 'CARDINAL')]\n",
      "After [('Germany', 1, 2, 'GPE'), ('road', 3, 4, 'CI_TYPE'), ('1', 16, 17, 'CARDINAL'), ('EURO 2 billion Euro', 24, 28, 'MONEY'), ('MDR', 29, 30, 'ORG'), ('2021', 31, 32, 'DATE'), ('More than 130 km', 34, 38, 'QUANTITY'), ('50 km', 49, 51, 'QUANTITY'), ('two months later', 54, 57, 'DATE'), ('EUR 100 million', 64, 67, 'MONEY'), ('Hauser', 68, 69, 'ORG'), ('2021', 70, 71, 'DATE'), ('112', 75, 76, 'CARDINAL'), ('40 km', 80, 82, 'QUANTITY'), ('the Ahr valley', 83, 86, 'LOC'), ('Rhineland-Palatinate', 87, 90, 'GPE'), ('62', 92, 93, 'CARDINAL'), ('13', 97, 98, 'CARDINAL'), ('only 35', 102, 104, 'CARDINAL'), ('a month', 107, 109, 'DATE'), ('MDR', 114, 115, 'GPE'), ('2021', 116, 117, 'DATE'), ('74 km', 120, 122, 'QUANTITY'), ('the Ahr valley', 129, 132, 'LOC'), ('months to years', 148, 151, 'DATE'), ('Zeit Online', 152, 154, 'ORG'), ('2021', 155, 156, 'DATE'), ('ma- jor', 161, 163, 'LOC'), ('A1', 170, 171, 'FAC'), ('early 2022', 176, 178, 'DATE'), ('24Rhein', 179, 180, 'ORG'), ('2022', 181, 182, 'DATE'), ('about 50 000', 187, 190, 'CARDINAL'), ('some EUR 450 million', 198, 202, 'MONEY'), ('ADAC', 203, 204, 'ORG'), ('2021', 205, 206, 'DATE'), ('German', 209, 210, 'NORP'), ('Deutsche Bahn', 212, 214, 'ORG'), ('around EUR 1.3 billion', 218, 222, 'MONEY'), ('180', 227, 228, 'CARDINAL')]\n"
     ]
    }
   ],
   "source": [
    "## Left overs \n",
    "## adds new entity but based on Span(), index position wihtin text\n",
    "\n",
    "\n",
    "# import spacy\n",
    "# from spacy.tokens import Span\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "\n",
    "# PARSED_TEXT_DIR = \"../\" + s.settings.PATH_DATA + \"parsed_documents/\"\n",
    "# FILE_PATH = PARSED_TEXT_DIR + \"Koks et al 2022 Brief communication_cleaned.md\"\n",
    "\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# loader = DoclingLoader(FILE_PATH)  # use chunks from Docling.Loader\n",
    "# doc = loader.load()\n",
    "\n",
    "\n",
    "# ## testing for chunk [6]:\n",
    "\n",
    "# chunk_6 = nlp(doc[6].page_content)\n",
    "\n",
    "# print(f\"\\n chunk text [6]:\", doc[6].page_content)\n",
    "# ents = [(e.text, e.start_char, e.end_char, e.label_) for e in chunk_6.ents]\n",
    "# print('Before', ents)\n",
    "\n",
    "# # Create a span for the new entity\n",
    "# road_ent = Span(chunk_6, 3, 4, label=\"CI_TYPE\") \n",
    "# # railwayinfrastructure_ent = Span(chunk_6, 5, 7, label=\"CI_TYPE\") \n",
    "# orig_ents = list(chunk_6.ents)\n",
    "\n",
    "# # Option 1: Modify the provided entity spans, leaving the rest unmodified\n",
    "# chunk_6.set_ents([road_ent], default=\"unmodified\")\n",
    "# # chunk_6.ents = orig_ents + [road_ent]\n",
    "\n",
    "# ents = [(e.text, e.start, e.end, e.label_) for e in chunk_6.ents]\n",
    "# print('After', ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"./models/model-best\")\n",
    "# layout = spaCyLayout(nlp)\n",
    "\n",
    "# span = nlp_doc.ents[0]  # \"Apple Inc.\" (ORG)\n",
    "# for layout_span in nlp_doc.spans[\"layout\"]:\n",
    "#     if span.start >= layout_span.start:\n",
    "#         print(layout_span._.layout)  # bounding box\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "#### testing further NER approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "# from langchain.schema import Document as LCDocument\n",
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain.vectorstores.faiss import FAISS\n",
    "# from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import spacy\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s\n",
    "\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "\n",
    "## apply NER model on parsed documents\n",
    "PARSED_TEXT_DIR = \"../\" + s.settings.PATH_DATA + \"parsed_documents/\"\n",
    "\n",
    "for filename in os.listdir(PARSED_TEXT_DIR):\n",
    "    if filename.endswith(\".md\"):\n",
    "        print(f\"\\nFetching: {filename}\")\n",
    "\n",
    "        FILE_PATH = PARSED_TEXT_DIR + filename\n",
    "\n",
    "        # Begin loading\n",
    "\n",
    "        if not os.path.exists(FILE_PATH):\n",
    "            print(f\"Error: File '{FILE_PATH}' does not exist.\")\n",
    "            exit(1)\n",
    "\n",
    "        loader = DoclingLoader(FILE_PATH)\n",
    "        doc = loader.load()\n",
    "\n",
    "        if doc:\n",
    "            print(f\"Loaded document with {len(doc)} characters\")\n",
    "            # Process with spaCy NLP\n",
    "            nlp_doc = nlp(doc.page_content)\n",
    "            print(f\"Processed document with spaCy - found {len(nlp_doc.ents)} entities\")\n",
    "        else:\n",
    "            print(\"No document loaded\")\n",
    "\n",
    "\n",
    "# # Extract text blocks (paragraphs, etc.)\n",
    "# blocks = doc.text_blocks  # each block has: .text, .bbox, .page_no\n",
    "\n",
    "# print(f\"Parsed {len(blocks)} structural blocks from PDF\")\n",
    "# blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SPACY NER ON EACH BLOCK\n",
    "lc_docs = []  # LangChain document objects\n",
    "\n",
    "for block in blocks:\n",
    "    text = block.text.strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    spacy_doc = nlp(text)\n",
    "    ents, chars = [\n",
    "        (ent.text, ent.label_)(ent.start_char, ent.end_char) for ent in spacy_doc.ents\n",
    "    ]\n",
    "\n",
    "    metadata = {\n",
    "        \"page\": block.page_no,\n",
    "        \"entities\": ents,\n",
    "        \"start_end_char\": chars,\n",
    "    }\n",
    "    print(metadata)\n",
    "    # lc_docs.append(LCDocument(page_content=text, metadata=metadata))\n",
    "\n",
    "print(f\"Created {len(lc_docs)} LangChain documents with NER metadata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract JSON region\n",
    "\n",
    "\n",
    "# try:\n",
    "#     items = json.loads(json_str)\n",
    "# except Exception:\n",
    "#     raise ValueError(f\"Model did not produce valid JSON:\\n\\n{response}\")\n",
    "\n",
    "\n",
    "# # -------------------------\n",
    "# # 6. Enhance Location via NER\n",
    "# # -------------------------\n",
    "\n",
    "\n",
    "# # Load NER Model (spaCy)\n",
    "# ner_model = spacy.load(\"en_core_web_sm\")  # or HF transformers NER model  # TODO fix this\n",
    "\n",
    "\n",
    "# def extract_location(text):\n",
    "#     doc = ner_model(text)\n",
    "#     ents = [ent.text for ent in doc.ents if ent.label_ in (\"GPE\", \"LOC\")]\n",
    "#     return ents[0] if ents else text  # fallback: original field\n",
    "\n",
    "# for item in response:\n",
    "#     item[\"location\"] = extract_location(item.get(\"location\", \"\"))\n",
    "\n",
    "# -------------------------\n",
    "# 7. Convert to DataFrame (tabular output)\n",
    "# -------------------------\n",
    "df = pd.DataFrame(response)\n",
    "\n",
    "print(\"\\n=== Final Tabular Output ===\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "## create workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.settings as s\n",
    "from src.database import connect_db, fill_db, TextSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill db\n",
    "\n",
    "DOCS_DIR = \"../\" + s.settings.PATH_DATA + \"text_sources/\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(DOCS_DIR):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        print(f\"fetching: {filename}\")\n",
    "\n",
    "        file_path = os.path.join(DOCS_DIR, filename)\n",
    "        text = extract_text(file_path)\n",
    "        filename = Path(filename).stem\n",
    "        authors, title = authors, title = (\n",
    "            re.compile(r\"(.+?)[0-9]{4}(.*)?\").search(filename).groups()\n",
    "        )\n",
    "\n",
    "        entry = {\n",
    "            \"authors\": authors.strip(),\n",
    "            \"title\": title.strip(),\n",
    "            \"source\": \"dummy source\",\n",
    "            \"content\": text,\n",
    "            \"metadata\": {\n",
    "                \"tags\": [\"ahr_valley\", \"dummy_publication_type\"],\n",
    "                \"published_date\": re.findall(r\"[0-9]{4}\", filename)[0],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    fill_db(TextSource(**entry))  # TODO make fill_Db() as async function\n",
    "\n",
    "# connect to database and insert automatically all pdf files stored in data folder\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class WikiSearchResult:\n",
    "#     id: int\n",
    "#     url: str\n",
    "#     title: str\n",
    "#     text: str\n",
    "#     chunk: str\n",
    "#     distance: float\n",
    "\n",
    "# def insert_article_about_pgai(conn: psycopg.AsyncConnection):\n",
    "#     async with conn.cursor(row_factory=class_row(WikiSearchResult)) as cur:\n",
    "#         await cur.execute(\"\"\"\n",
    "#             INSERT INTO wiki (url, title, text) VALUES\n",
    "#             ('https://en.wikipedia.org/wiki/pgai', 'pgai', 'pgai is a Python library that turns PostgreSQL into the retrieval engine behind robust, production-ready RAG and Agentic applications. It does this by automatically creating vector embeddings for your data based on the vectorizer you define.')\n",
    "#         \"\"\")\n",
    "#     await conn.commit()\n",
    "\n",
    "\n",
    "# ## delete table\n",
    "# conn = connect_db()\n",
    "# curs = conn.cursor()\n",
    "# curs.execute('DROP TABLE IF EXISTS text_source;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgai\n",
    "\n",
    "DB_URL = \"postgres://postgres:postgres@localhost:5432/postgres\"\n",
    "# DATABASE_URL=postgres://[user]:[password]@[host]:[port]/[database]\n",
    "pgai.install(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test different embedding models\n",
    "# https://www.tigerdata.com/blog/finding-the-best-open-source-embedding-model-for-rag\n",
    "\n",
    "# TODO make create-vecotrizer as async function\n",
    "\n",
    "import asyncio\n",
    "import psycopg as pg\n",
    "from src.database import connect_db\n",
    "\n",
    "\n",
    "async def create_vectorizer(\n",
    "    conn: pg.AsyncConnection, embedding_model, embeddings_dimensions\n",
    "):\n",
    "\n",
    "    embeddings_view_name = f\"{embedding_model.replace('-', '_')}{'_content_embeddings'}\"\n",
    "\n",
    "    # TODO make connect_db() as asyncConnection\n",
    "\n",
    "    async with conn.cursor() as curs:\n",
    "        await curs.execute(\n",
    "            f\"\"\"\n",
    "                SELECT ai.create_vectorizer(\n",
    "                    'public.text_source'::regclass,\n",
    "                    if_not_exists => true,\n",
    "                    loading => ai.loading_column(column_name => 'content'),\n",
    "                    embedding => ai.embedding_ollama('{embedding_model}', {embeddings_dimensions}),\n",
    "                    chunking => ai.chunking_recursive_character_text_splitter(\n",
    "                        {embeddings_dimensions}, {s.settings.CHUNK_OVERLAP},\n",
    "                        separators => array[E'\\n\\n', E'\\n', '. ']\n",
    "                    ),\n",
    "                    destination =>  ai.destination_table(view_name => '{embeddings_view_name}'),\n",
    "                    formatting => ai.formatting_python_template('authors - title: $authors - $title, chunk: $chunk')\n",
    "                );\"\"\"\n",
    "        )\n",
    "    await conn.commit()\n",
    "\n",
    "    curs.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# destination => {embeddings_view_name},  # Alternative to table: making just as a view\n",
    "#  public.destination_table({embeddings_table_name})\n",
    "#  public.chunking_character_text_splitter(128, 10, E'\\n'),\n",
    "#   embedding => public.embedding_ollama({embedding_model}, {embeddings_dimensions}),\n",
    "# formating:  add the title of the document as the first line of the chunk\n",
    "\n",
    "EMBEDDING_MODELS = [\n",
    "    # {\"name\": \"all-minilm\", \"dimensions\": 384}\n",
    "    {\"name\": \"nomic-embed-text\", \"dimensions\": 768},\n",
    "    # {\"name\": \"mxbai-embed-large\", \"dimensions\": 1024},\n",
    "    # {\"name\": \"bge-m3\", \"dimensions\": 1024},\n",
    "]\n",
    "\n",
    "for model in EMBEDDING_MODELS:\n",
    "    create_vectorizer(connect_db(), model[\"name\"], model[\"dimensions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the vectorizer worker once to create the embeddings for the existing data.\n",
    "\n",
    "import asyncio\n",
    "from pgai import Worker\n",
    "\n",
    "# DATABASE_URL=postgres://[user]:[password]@[host]:[port]/[database]\n",
    "DB_URL = \"postgres://postgres:postgres@vectordb:5432/postgres\"  # same as compose yaml for vectorizer\n",
    "# DB_URL = \"postgres://postgres:postgres@localhost:5432/vectordb\" # TODO as s.settings.DATABASE_URL\n",
    "worker = Worker(DB_URL, once=True)\n",
    "worker.run()\n",
    "\n",
    "# # OR run You can run the worker in the background from the application, the cli, or docker. See the vectorizer worker documentation for more details.\n",
    "# # https://github.com/timescale/pgai/blob/main/docs/vectorizer/worker.md\n",
    "\n",
    "# worker = pgai.Worker(db_url=DB_URL)\n",
    "# task = asyncio.create_task(worker.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check entries\n",
    "conn = connect_db()\n",
    "curs = conn.cursor()\n",
    "\n",
    "curs.execute(\"SELECT * FROM nomic_embed_text_content_embeddings;\")\n",
    "rows = curs.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Clean up\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "# # # Extract the context text from the response\n",
    "# context = \"\".join(context_response[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_db(\"SELECT * FROM ai.vectorizer_status;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load all embedded docs from pgai postgres DB and apply LLM\n",
    "\n",
    "\n",
    "## # https://www.tigerdata.com/blog/finding-the-best-open-source-embedding-model-for-rag\n",
    "\n",
    "# def fetch_similar_chunks(question: str, top_k: int = 5):\n",
    "#     with connect_db() as conn:\n",
    "#         with conn.cursor() as curs:\n",
    "#             curs.execute(\n",
    "#                 f\"\"\"\n",
    "#                 SELECT content, ai.cosine_distance(\n",
    "#                     ai.embedding_ollama('nomic-embed-text', 768, %s),\n",
    "#                     embedding\n",
    "#                 ) AS distance\n",
    "#                 FROM nomic_embed_text_content_embeddings\n",
    "#                 ORDER BY distance ASC\n",
    "#                 LIMIT %s;\n",
    "#                 \"\"\",\n",
    "#             (question, top_k),\n",
    "#         )\n",
    "#         results = curs.fetchall()\n",
    "# return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the context text from the response\n",
    "context = \"\".join(context_response[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "## Left overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured_llm.py\n",
    "import json\n",
    "from typing import Type, Optional\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "\n",
    "\n",
    "class StructuredLLM:\n",
    "    \"\"\"\n",
    "    A minimal drop-in replacement for Instructor,\n",
    "    but works locally with HuggingFace models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_retries: int = 2,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def _generate(self, prompt: str, max_new_tokens=512) -> str:\n",
    "        \"\"\"Low-level text generation.\"\"\"\n",
    "        inputs = self.tokenizer(prompt)  # , #return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def __call__(self, prompt: str, response_model: Type[BaseModel]):\n",
    "        \"\"\"High-level structured LLM call.\"\"\"\n",
    "        schema = response_model.schema()\n",
    "\n",
    "        system_instruction = f\"\"\"\n",
    "            You MUST respond ONLY with valid JSON that matches this exact schema:\n",
    "            {json.dumps(schema, indent=2)}\n",
    "            If you cannot answer, return JSON with empty strings or null values.\n",
    "        \"\"\"\n",
    "\n",
    "        full_prompt = system_instruction + \"\\n\\nUser Prompt:\\n\" + prompt\n",
    "\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            raw = self._generate(full_prompt)\n",
    "\n",
    "            try:\n",
    "                json_str = self._extract_json(raw)\n",
    "                parsed = response_model.parse_raw(json_str)\n",
    "                return parsed\n",
    "\n",
    "            except Exception:\n",
    "                if attempt == self.max_retries:\n",
    "                    raise ValueError(\n",
    "                        f\"Could not parse valid structured output.\\nRaw output:\\n{raw}\"\n",
    "                    )\n",
    "\n",
    "        raise RuntimeError(\"Unexpected error in the structured LLM wrapper.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_json(text: str) -> str:\n",
    "        \"\"\"Extracts JSON substring from messy LLM output.\"\"\"\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\") + 1\n",
    "        if start == -1 or end == -1:\n",
    "            raise ValueError(\"No JSON found in output.\")\n",
    "        return text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name: str, model_dir: str = None, bnb_config=None):\n",
    "\n",
    "    # Model and Tokenizer initialization\n",
    "    if not os.path.exists(model_dir):\n",
    "        print(\"Model directory not found. Downloading model...\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        device = transformers.infer_device()\n",
    "        print(f\"Using device: {device}\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            local_files_only=True,\n",
    "        )\n",
    "        model.save_pretrained(model_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "        print(\"Downloaded model and tokenizer\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Using locally saved model from {model_dir}\")\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            cache_dir=model_dir,\n",
    "            local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "            dtype=\"auto\",\n",
    "            attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "            # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "            quantization_config=bnb_config,\n",
    "            # max_memory={0: \"2GB\", 1: \"10GB\"},  # distribute memory across GPUs\n",
    "        )\n",
    "        print(\"Tensor parallel plan:\", model._tp_plan)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name, use_fast=True, cache_dir=model_dir\n",
    "        )\n",
    "\n",
    "    # reduce further memory usage\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.use_checkpointing = True\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Pipeline setup for question answering\n",
    "    pipeline = transformers.pipeline(  # load model locally from wsl .cache\\\n",
    "        \"text-generation\",\n",
    "        # \"question-answering\",  # task defining which pipeline is returned\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,  # load specific tokenizer based on model-name (via AutoTokenizer) ensuring text is tokenized in accordance to the way the model was trained\n",
    "        max_new_tokens=256,\n",
    "        # dtype=np.float16,\n",
    "        # low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    return pipeline, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# 1. Load model\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # \"Qwen/Qwen1.5-0.5B-Chat\" #\n",
    "base_dir = \"./huggingface_mirror\"  # use default dir in .cache/\n",
    "model_dir = base_dir + \"/hub/\"  # + \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "print(model_dir)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=model_dir,\n",
    "    local_files_only=True,  # tp_plan=\"auto\" # set tensor parallel model (ie. splits model on multiple GPU)\n",
    "    dtype=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",  # use with 4-bit quantization,\n",
    "    # --> flash attention enables to use much larger sequence lengths without running into OOM issues\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, use_fast=True, cache_dir=model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Wrap in StructuredLLM\n",
    "llm = StructuredLLM(model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# 3. Define Pydantic schema\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "# 4. Type-safe extraction!\n",
    "result = llm(\"What is the capital of France?\", response_model=Answer)\n",
    "\n",
    "print(result)\n",
    "print(\"Parsed answer:\", result.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "### sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(  # load model locally from wsl .cache\\\n",
    "    \"text-generation\",\n",
    "    # \"question-answering\",  # task defining which pipeline is returned\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,  # (return_tensors=\"pt\"),  # load specific tokenizer based on model-name (via AutoTokenizer) ensuring text is tokenized in accordance to the way the model was trained\n",
    "    max_new_tokens=256,\n",
    "    # low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "llm = StructuredLLM(pipe.model, pipe.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-impacts-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
